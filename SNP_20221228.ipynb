{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RT6fgzwQPxJTlfbhe0rxG5CRQLhF3-RP",
      "authorship_tag": "ABX9TyMnf26ow2DSsmjxtY8tmnCT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jellyho/DACON/blob/master/SNP_20221228.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NSsjLywb3BOe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "data_path = '/content/drive/MyDrive/DACON/SNP/'\n",
        "\n",
        "train = pd.read_csv(data_path + 'train.csv')\n",
        "test = pd.read_csv(data_path + 'test.csv')\n",
        "info = pd.read_csv(data_path + 'snp_info.csv')\n",
        "submission = pd.read_csv(data_path + 'sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "biMxWFPDh1gC",
        "outputId": "b6787d0d-0afb-4f17-8d27-88061b9ca932"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id  father  mother  gender  trait SNP_01 SNP_02 SNP_03 SNP_04  \\\n",
              "0    TRAIN_000       0       0       0      2    G G    A G    A A    G A   \n",
              "1    TRAIN_001       0       0       0      2    A G    A G    C A    A A   \n",
              "2    TRAIN_002       0       0       0      2    G G    G G    A A    G A   \n",
              "3    TRAIN_003       0       0       0      1    A A    G G    A A    G A   \n",
              "4    TRAIN_004       0       0       0      2    G G    G G    C C    A A   \n",
              "..         ...     ...     ...     ...    ...    ...    ...    ...    ...   \n",
              "257  TRAIN_257       0       0       0      2    A G    A G    A A    G A   \n",
              "258  TRAIN_258       0       0       0      2    G G    A A    C A    A A   \n",
              "259  TRAIN_259       0       0       0      1    A G    G G    A A    G A   \n",
              "260  TRAIN_260       0       0       0      1    A A    G G    A A    G A   \n",
              "261  TRAIN_261       0       0       0      2    G G    A G    C A    G G   \n",
              "\n",
              "    SNP_05  ... SNP_07 SNP_08 SNP_09 SNP_10 SNP_11 SNP_12 SNP_13 SNP_14  \\\n",
              "0      C A  ...    A A    G G    A A    G G    A G    A A    A A    A A   \n",
              "1      A A  ...    A A    G A    A A    A G    A A    G A    G G    A A   \n",
              "2      C C  ...    A A    G A    G A    A G    A A    A A    A A    A A   \n",
              "3      A A  ...    G G    A A    G G    A G    G G    G G    G G    A A   \n",
              "4      C C  ...    A A    A A    A A    G G    A A    A A    A G    A A   \n",
              "..     ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
              "257    C C  ...    A A    G A    A A    G G    A G    G A    A A    A A   \n",
              "258    A A  ...    G A    G A    A A    A G    A G    A A    A G    A A   \n",
              "259    A A  ...    G G    G A    G A    A A    G G    G G    G G    C A   \n",
              "260    A A  ...    G G    A A    G A    A G    A G    G A    G G    C A   \n",
              "261    C C  ...    A A    A A    A A    G G    A A    A A    G G    A A   \n",
              "\n",
              "    SNP_15 class  \n",
              "0      A A     B  \n",
              "1      A A     C  \n",
              "2      A A     B  \n",
              "3      G G     A  \n",
              "4      G A     C  \n",
              "..     ...   ...  \n",
              "257    A A     B  \n",
              "258    G A     C  \n",
              "259    G G     A  \n",
              "260    G G     A  \n",
              "261    G A     B  \n",
              "\n",
              "[262 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfe06473-351b-4f74-a84b-e3a0eb98dcce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>father</th>\n",
              "      <th>mother</th>\n",
              "      <th>gender</th>\n",
              "      <th>trait</th>\n",
              "      <th>SNP_01</th>\n",
              "      <th>SNP_02</th>\n",
              "      <th>SNP_03</th>\n",
              "      <th>SNP_04</th>\n",
              "      <th>SNP_05</th>\n",
              "      <th>...</th>\n",
              "      <th>SNP_07</th>\n",
              "      <th>SNP_08</th>\n",
              "      <th>SNP_09</th>\n",
              "      <th>SNP_10</th>\n",
              "      <th>SNP_11</th>\n",
              "      <th>SNP_12</th>\n",
              "      <th>SNP_13</th>\n",
              "      <th>SNP_14</th>\n",
              "      <th>SNP_15</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>C A</td>\n",
              "      <td>...</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRAIN_001</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>A G</td>\n",
              "      <td>A G</td>\n",
              "      <td>C A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>...</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TRAIN_002</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>G G</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>C C</td>\n",
              "      <td>...</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TRAIN_003</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>...</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>G G</td>\n",
              "      <td>G G</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TRAIN_004</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>G G</td>\n",
              "      <td>G G</td>\n",
              "      <td>C C</td>\n",
              "      <td>A A</td>\n",
              "      <td>C C</td>\n",
              "      <td>...</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>TRAIN_257</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>A G</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>C C</td>\n",
              "      <td>...</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>TRAIN_258</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>C A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>...</td>\n",
              "      <td>G A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>TRAIN_259</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>A G</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>...</td>\n",
              "      <td>G G</td>\n",
              "      <td>G A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>G G</td>\n",
              "      <td>G G</td>\n",
              "      <td>C A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>TRAIN_260</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>...</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A G</td>\n",
              "      <td>G A</td>\n",
              "      <td>G G</td>\n",
              "      <td>C A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>TRAIN_261</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>C A</td>\n",
              "      <td>G G</td>\n",
              "      <td>C C</td>\n",
              "      <td>...</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfe06473-351b-4f74-a84b-e3a0eb98dcce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cfe06473-351b-4f74-a84b-e3a0eb98dcce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cfe06473-351b-4f74-a84b-e3a0eb98dcce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "일단 염기서열을 SNP_01_01, 02로 가서 각각을 one_hot encoding으로 조져 그러면 각 그거당 4개의 열을 사용하면 됨."
      ],
      "metadata": {
        "id": "T2b8RgkvGzhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "xt9tM9Nu4Ash",
        "outputId": "d6da9a15-891d-44f4-bb53-57e96585d4db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    SNP_id                                   name  chrom        cm       pos\n",
              "0   SNP_01                        BTA-19852-no-rs      2  67.05460  42986890\n",
              "1   SNP_02  ARS-USMARC-Parent-DQ647190-rs29013632      6  31.15670  13897068\n",
              "2   SNP_03                    ARS-BFGL-NGS-117009      6  68.28920  44649549\n",
              "3   SNP_04                     ARS-BFGL-NGS-60567      6  77.87490  53826064\n",
              "4   SNP_05                     BovineHD0600017032      6  80.50150  61779512\n",
              "5   SNP_06                     BovineHD0600017424      6  80.59540  63048481\n",
              "6   SNP_07                 Hapmap49442-BTA-111073      6  80.78000  64037334\n",
              "7   SNP_08                     BovineHD0600018638      6  82.68560  67510588\n",
              "8   SNP_09                     ARS-BFGL-NGS-37727      6  86.87400  73092782\n",
              "9   SNP_10                           BTB-01558306      7  62.06920  40827112\n",
              "10  SNP_11                     ARS-BFGL-NGS-44247      8  97.17310  92485682\n",
              "11  SNP_12                 Hapmap32827-BTA-146530      9  62.74630  55007839\n",
              "12  SNP_13                           BTB-00395482      9  63.41810  59692848\n",
              "13  SNP_14                  Hapmap40256-BTA-84189      9  66.81970  72822507\n",
              "14  SNP_15                     BovineHD1000000224     10   1.78774    814291"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c97685e-1d66-499a-a92b-97b5f561c5d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SNP_id</th>\n",
              "      <th>name</th>\n",
              "      <th>chrom</th>\n",
              "      <th>cm</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SNP_01</td>\n",
              "      <td>BTA-19852-no-rs</td>\n",
              "      <td>2</td>\n",
              "      <td>67.05460</td>\n",
              "      <td>42986890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SNP_02</td>\n",
              "      <td>ARS-USMARC-Parent-DQ647190-rs29013632</td>\n",
              "      <td>6</td>\n",
              "      <td>31.15670</td>\n",
              "      <td>13897068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SNP_03</td>\n",
              "      <td>ARS-BFGL-NGS-117009</td>\n",
              "      <td>6</td>\n",
              "      <td>68.28920</td>\n",
              "      <td>44649549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SNP_04</td>\n",
              "      <td>ARS-BFGL-NGS-60567</td>\n",
              "      <td>6</td>\n",
              "      <td>77.87490</td>\n",
              "      <td>53826064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SNP_05</td>\n",
              "      <td>BovineHD0600017032</td>\n",
              "      <td>6</td>\n",
              "      <td>80.50150</td>\n",
              "      <td>61779512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SNP_06</td>\n",
              "      <td>BovineHD0600017424</td>\n",
              "      <td>6</td>\n",
              "      <td>80.59540</td>\n",
              "      <td>63048481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SNP_07</td>\n",
              "      <td>Hapmap49442-BTA-111073</td>\n",
              "      <td>6</td>\n",
              "      <td>80.78000</td>\n",
              "      <td>64037334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SNP_08</td>\n",
              "      <td>BovineHD0600018638</td>\n",
              "      <td>6</td>\n",
              "      <td>82.68560</td>\n",
              "      <td>67510588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SNP_09</td>\n",
              "      <td>ARS-BFGL-NGS-37727</td>\n",
              "      <td>6</td>\n",
              "      <td>86.87400</td>\n",
              "      <td>73092782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SNP_10</td>\n",
              "      <td>BTB-01558306</td>\n",
              "      <td>7</td>\n",
              "      <td>62.06920</td>\n",
              "      <td>40827112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SNP_11</td>\n",
              "      <td>ARS-BFGL-NGS-44247</td>\n",
              "      <td>8</td>\n",
              "      <td>97.17310</td>\n",
              "      <td>92485682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>SNP_12</td>\n",
              "      <td>Hapmap32827-BTA-146530</td>\n",
              "      <td>9</td>\n",
              "      <td>62.74630</td>\n",
              "      <td>55007839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>SNP_13</td>\n",
              "      <td>BTB-00395482</td>\n",
              "      <td>9</td>\n",
              "      <td>63.41810</td>\n",
              "      <td>59692848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>SNP_14</td>\n",
              "      <td>Hapmap40256-BTA-84189</td>\n",
              "      <td>9</td>\n",
              "      <td>66.81970</td>\n",
              "      <td>72822507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>SNP_15</td>\n",
              "      <td>BovineHD1000000224</td>\n",
              "      <td>10</td>\n",
              "      <td>1.78774</td>\n",
              "      <td>814291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c97685e-1d66-499a-a92b-97b5f561c5d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c97685e-1d66-499a-a92b-97b5f561c5d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c97685e-1d66-499a-a92b-97b5f561c5d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "mc = MinMaxScaler()\n",
        "\n",
        "data = info[['chrom', 'cm', 'pos']]\n",
        "data = sc.fit_transform(data)\n",
        "pca = PCA(n_components=1)\n",
        "info_factor = pca.fit_transform(data)\n",
        "info_factor = mc.fit_transform(info_factor)"
      ],
      "metadata": {
        "id": "HiqNcJAqFxJv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_processing(df, isTrain=True):\n",
        "  df = df.drop(columns=['father', 'mother', 'gender', 'id'])\n",
        "  dic0 = {'A':0, 'T':0, 'G':1, 'C':1}\n",
        "  dic1 = {'A':0, 'T':1, 'G':0, 'C':1}\n",
        "  dicClass = {'A':0, 'B':1, 'C':2}\n",
        "  dictrait = {1:0, 2:1}\n",
        "  for i in range(1, 16):\n",
        "    l0 = []\n",
        "    l1 = []\n",
        "    l2 = []\n",
        "    l3 = []\n",
        "    value = df[f\"SNP_{'0'if i < 10 else ''}{i}\"].values\n",
        "    for v in value:\n",
        "      s = v.split(' ')\n",
        "      l0.append(dic0[s[0]])\n",
        "      l1.append(dic1[s[0]])\n",
        "      l2.append(dic0[s[1]])\n",
        "      l3.append(dic1[s[1]])\n",
        "    df[f\"SNP_{'0'if i < 10 else ''}{i}_0\"] = l0\n",
        "    df[f\"SNP_{'0'if i < 10 else ''}{i}_1\"] = l1\n",
        "    df[f\"SNP_{'0'if i < 10 else ''}{i}_2\"] = l2\n",
        "    df[f\"SNP_{'0'if i < 10 else ''}{i}_3\"] = l3\n",
        "    df[f\"Mul_SNP_{'0'if i < 10 else ''}{i}_0\"] = l0 * info_factor[i-1]\n",
        "    df[f\"Mul_SNP_{'0'if i < 10 else ''}{i}_1\"] = l1 * info_factor[i-1]\n",
        "    df[f\"Mul_SNP_{'0'if i < 10 else ''}{i}_2\"] = l2 * info_factor[i-1]\n",
        "    df[f\"Mul_SNP_{'0'if i < 10 else ''}{i}_3\"] = l3 * info_factor[i-1]\n",
        "\n",
        "  df = df.drop(columns=[f\"SNP_{'0'if j < 10 else ''}{j}\" for j in range(1, 16)])\n",
        "  df['trait'] = df['trait'].apply(lambda x: dictrait[x])\n",
        "  if isTrain:\n",
        "    df['class'] = df['class'].apply(lambda x: dicClass[x])\n",
        "    return df.drop(columns=['class']), df['class'].values\n",
        "  else:\n",
        "    return df"
      ],
      "metadata": {
        "id": "qGJwwSOqE5Ji"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, train_y = pre_processing(train)\n",
        "test_X = pre_processing(test, False)"
      ],
      "metadata": {
        "id": "UUq3bzXCrrQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae90945e-f130-4f7e-ed5a-27b2c1a479a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-db077193c942>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f\"SNP_{'0'if i < 10 else ''}{i}_2\"] = l2\n",
            "<ipython-input-12-db077193c942>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f\"SNP_{'0'if i < 10 else ''}{i}_3\"] = l3\n",
            "<ipython-input-12-db077193c942>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f\"Mul_SNP_{'0'if i < 10 else ''}{i}_0\"] = l0 * info_factor[i-1]\n",
            "<ipython-input-12-db077193c942>:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f\"Mul_SNP_{'0'if i < 10 else ''}{i}_1\"] = l1 * info_factor[i-1]\n",
            "<ipython-input-12-db077193c942>:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f\"Mul_SNP_{'0'if i < 10 else ''}{i}_2\"] = l2 * info_factor[i-1]\n",
            "<ipython-input-12-db077193c942>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f\"Mul_SNP_{'0'if i < 10 else ''}{i}_3\"] = l3 * info_factor[i-1]\n",
            "<ipython-input-12-db077193c942>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f\"SNP_{'0'if i < 10 else ''}{i}_0\"] = l0\n",
            "<ipython-input-12-db077193c942>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f\"SNP_{'0'if i < 10 else ''}{i}_1\"] = l1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgbm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=50).split(train_X, train_y)\n",
        "\n",
        "lgbm_models = []\n",
        "lgbm_scores = []\n",
        "\n",
        "for (ktrain, kvalid) in kfold:\n",
        "  dtrain = lgbm.Dataset(train_X.iloc[ktrain, :], train_y[ktrain])\n",
        "  dvalid = lgbm.Dataset(train_X.iloc[kvalid, :], train_y[kvalid])\n",
        "  params = {'objective': 'multiclass', 'num_class':3, 'force_col_wise': True, 'bagging_freq': 1, 'learning_rate': 0.001, 'random_state':413}\n",
        "  model= lgbm.train(params=params, train_set=dtrain, num_boost_round=100000, valid_sets=dvalid, early_stopping_rounds=2000, verbose_eval=1000)\n",
        "  pred = model.predict(train_X.iloc[kvalid, :])\n",
        "  score = log_loss(train_y[kvalid], pred)\n",
        "  if score < 1e-5:\n",
        "    lgbm_scores.append(score)\n",
        "    lgbm_models.append(model)"
      ],
      "metadata": {
        "id": "IY7e9Kxu5eAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbbd3eef-85cd-4ecd-f2fa-3346efa72e08"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.497145\n",
            "[2000]\tvalid_0's multi_logloss: 0.266403\n",
            "[3000]\tvalid_0's multi_logloss: 0.14306\n",
            "[4000]\tvalid_0's multi_logloss: 0.0772544\n",
            "[5000]\tvalid_0's multi_logloss: 0.0461213\n",
            "[6000]\tvalid_0's multi_logloss: 0.0285288\n",
            "[7000]\tvalid_0's multi_logloss: 0.0150809\n",
            "[8000]\tvalid_0's multi_logloss: 0.00889926\n",
            "[9000]\tvalid_0's multi_logloss: 0.00605378\n",
            "[10000]\tvalid_0's multi_logloss: 0.00458639\n",
            "[11000]\tvalid_0's multi_logloss: 0.00340182\n",
            "[12000]\tvalid_0's multi_logloss: 0.00282819\n",
            "[13000]\tvalid_0's multi_logloss: 0.00233249\n",
            "[14000]\tvalid_0's multi_logloss: 0.00169267\n",
            "[15000]\tvalid_0's multi_logloss: 0.0011542\n",
            "[16000]\tvalid_0's multi_logloss: 0.000889434\n",
            "[17000]\tvalid_0's multi_logloss: 0.000757127\n",
            "[18000]\tvalid_0's multi_logloss: 0.000582713\n",
            "[19000]\tvalid_0's multi_logloss: 0.000418628\n",
            "[20000]\tvalid_0's multi_logloss: 0.000297102\n",
            "[21000]\tvalid_0's multi_logloss: 0.00022067\n",
            "[22000]\tvalid_0's multi_logloss: 0.000152641\n",
            "[23000]\tvalid_0's multi_logloss: 0.000102439\n",
            "[24000]\tvalid_0's multi_logloss: 6.91036e-05\n",
            "[25000]\tvalid_0's multi_logloss: 4.79113e-05\n",
            "[26000]\tvalid_0's multi_logloss: 3.38741e-05\n",
            "[27000]\tvalid_0's multi_logloss: 2.368e-05\n",
            "[28000]\tvalid_0's multi_logloss: 1.78253e-05\n",
            "[29000]\tvalid_0's multi_logloss: 1.49424e-05\n",
            "[30000]\tvalid_0's multi_logloss: 1.39257e-05\n",
            "[31000]\tvalid_0's multi_logloss: 1.12718e-05\n",
            "[32000]\tvalid_0's multi_logloss: 9.20786e-06\n",
            "[33000]\tvalid_0's multi_logloss: 7.63665e-06\n",
            "[34000]\tvalid_0's multi_logloss: 6.5836e-06\n",
            "[35000]\tvalid_0's multi_logloss: 5.90403e-06\n",
            "[36000]\tvalid_0's multi_logloss: 4.92575e-06\n",
            "[37000]\tvalid_0's multi_logloss: 3.86826e-06\n",
            "[38000]\tvalid_0's multi_logloss: 2.87553e-06\n",
            "[39000]\tvalid_0's multi_logloss: 2.02713e-06\n",
            "[40000]\tvalid_0's multi_logloss: 1.7151e-06\n",
            "[41000]\tvalid_0's multi_logloss: 1.50492e-06\n",
            "[42000]\tvalid_0's multi_logloss: 1.30805e-06\n",
            "[43000]\tvalid_0's multi_logloss: 1.11622e-06\n",
            "[44000]\tvalid_0's multi_logloss: 9.91675e-07\n",
            "[45000]\tvalid_0's multi_logloss: 9.14222e-07\n",
            "[46000]\tvalid_0's multi_logloss: 8.59761e-07\n",
            "[47000]\tvalid_0's multi_logloss: 8.2723e-07\n",
            "[48000]\tvalid_0's multi_logloss: 7.9878e-07\n",
            "[49000]\tvalid_0's multi_logloss: 7.49735e-07\n",
            "[50000]\tvalid_0's multi_logloss: 7.27677e-07\n",
            "[51000]\tvalid_0's multi_logloss: 7.11281e-07\n",
            "[52000]\tvalid_0's multi_logloss: 7.13823e-07\n",
            "[53000]\tvalid_0's multi_logloss: 7.09224e-07\n",
            "Early stopping, best iteration is:\n",
            "[51698]\tvalid_0's multi_logloss: 7.04585e-07\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.634378\n",
            "[2000]\tvalid_0's multi_logloss: 0.48487\n",
            "[3000]\tvalid_0's multi_logloss: 0.429795\n",
            "[4000]\tvalid_0's multi_logloss: 0.379355\n",
            "[5000]\tvalid_0's multi_logloss: 0.342797\n",
            "[6000]\tvalid_0's multi_logloss: 0.340092\n",
            "[7000]\tvalid_0's multi_logloss: 0.384202\n",
            "Early stopping, best iteration is:\n",
            "[5617]\tvalid_0's multi_logloss: 0.332992\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.506198\n",
            "[2000]\tvalid_0's multi_logloss: 0.326049\n",
            "[3000]\tvalid_0's multi_logloss: 0.257436\n",
            "[4000]\tvalid_0's multi_logloss: 0.224392\n",
            "[5000]\tvalid_0's multi_logloss: 0.159996\n",
            "[6000]\tvalid_0's multi_logloss: 0.113851\n",
            "[7000]\tvalid_0's multi_logloss: 0.0870605\n",
            "[8000]\tvalid_0's multi_logloss: 0.0536827\n",
            "[9000]\tvalid_0's multi_logloss: 0.0368186\n",
            "[10000]\tvalid_0's multi_logloss: 0.0254132\n",
            "[11000]\tvalid_0's multi_logloss: 0.0218772\n",
            "[12000]\tvalid_0's multi_logloss: 0.024527\n",
            "Early stopping, best iteration is:\n",
            "[10598]\tvalid_0's multi_logloss: 0.0202205\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.46182\n",
            "[2000]\tvalid_0's multi_logloss: 0.21411\n",
            "[3000]\tvalid_0's multi_logloss: 0.118883\n",
            "[4000]\tvalid_0's multi_logloss: 0.0756058\n",
            "[5000]\tvalid_0's multi_logloss: 0.0506991\n",
            "[6000]\tvalid_0's multi_logloss: 0.0377749\n",
            "[7000]\tvalid_0's multi_logloss: 0.0302132\n",
            "[8000]\tvalid_0's multi_logloss: 0.0261448\n",
            "[9000]\tvalid_0's multi_logloss: 0.0240134\n",
            "[10000]\tvalid_0's multi_logloss: 0.0193116\n",
            "[11000]\tvalid_0's multi_logloss: 0.0152582\n",
            "[12000]\tvalid_0's multi_logloss: 0.0140151\n",
            "[13000]\tvalid_0's multi_logloss: 0.0129487\n",
            "[14000]\tvalid_0's multi_logloss: 0.0117506\n",
            "[15000]\tvalid_0's multi_logloss: 0.0111333\n",
            "[16000]\tvalid_0's multi_logloss: 0.0107971\n",
            "[17000]\tvalid_0's multi_logloss: 0.0092722\n",
            "[18000]\tvalid_0's multi_logloss: 0.0070303\n",
            "[19000]\tvalid_0's multi_logloss: 0.00531395\n",
            "[20000]\tvalid_0's multi_logloss: 0.00509751\n",
            "[21000]\tvalid_0's multi_logloss: 0.00445538\n",
            "[22000]\tvalid_0's multi_logloss: 0.003934\n",
            "[23000]\tvalid_0's multi_logloss: 0.00314978\n",
            "[24000]\tvalid_0's multi_logloss: 0.00230837\n",
            "[25000]\tvalid_0's multi_logloss: 0.00182116\n",
            "[26000]\tvalid_0's multi_logloss: 0.00142171\n",
            "[27000]\tvalid_0's multi_logloss: 0.00113441\n",
            "[28000]\tvalid_0's multi_logloss: 0.000924964\n",
            "[29000]\tvalid_0's multi_logloss: 0.00069041\n",
            "[30000]\tvalid_0's multi_logloss: 0.000483473\n",
            "[31000]\tvalid_0's multi_logloss: 0.000380938\n",
            "[32000]\tvalid_0's multi_logloss: 0.000319783\n",
            "[33000]\tvalid_0's multi_logloss: 0.000295254\n",
            "[34000]\tvalid_0's multi_logloss: 0.000250388\n",
            "[35000]\tvalid_0's multi_logloss: 0.000205338\n",
            "[36000]\tvalid_0's multi_logloss: 0.000162736\n",
            "[37000]\tvalid_0's multi_logloss: 0.000132292\n",
            "[38000]\tvalid_0's multi_logloss: 0.000107061\n",
            "[39000]\tvalid_0's multi_logloss: 8.89213e-05\n",
            "[40000]\tvalid_0's multi_logloss: 7.44111e-05\n",
            "[41000]\tvalid_0's multi_logloss: 6.79108e-05\n",
            "[42000]\tvalid_0's multi_logloss: 6.41287e-05\n",
            "[43000]\tvalid_0's multi_logloss: 5.62613e-05\n",
            "[44000]\tvalid_0's multi_logloss: 5.22457e-05\n",
            "[45000]\tvalid_0's multi_logloss: 4.58247e-05\n",
            "[46000]\tvalid_0's multi_logloss: 3.7767e-05\n",
            "[47000]\tvalid_0's multi_logloss: 3.3933e-05\n",
            "[48000]\tvalid_0's multi_logloss: 3.2961e-05\n",
            "[49000]\tvalid_0's multi_logloss: 3.04341e-05\n",
            "[50000]\tvalid_0's multi_logloss: 2.95747e-05\n",
            "[51000]\tvalid_0's multi_logloss: 3.00959e-05\n",
            "[52000]\tvalid_0's multi_logloss: 2.95333e-05\n",
            "Early stopping, best iteration is:\n",
            "[50184]\tvalid_0's multi_logloss: 2.94693e-05\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.469709\n",
            "[2000]\tvalid_0's multi_logloss: 0.266309\n",
            "[3000]\tvalid_0's multi_logloss: 0.151746\n",
            "[4000]\tvalid_0's multi_logloss: 0.0958038\n",
            "[5000]\tvalid_0's multi_logloss: 0.0560525\n",
            "[6000]\tvalid_0's multi_logloss: 0.0329775\n",
            "[7000]\tvalid_0's multi_logloss: 0.0206667\n",
            "[8000]\tvalid_0's multi_logloss: 0.0153831\n",
            "[9000]\tvalid_0's multi_logloss: 0.0113394\n",
            "[10000]\tvalid_0's multi_logloss: 0.00739315\n",
            "[11000]\tvalid_0's multi_logloss: 0.00517987\n",
            "[12000]\tvalid_0's multi_logloss: 0.00398291\n",
            "[13000]\tvalid_0's multi_logloss: 0.00330386\n",
            "[14000]\tvalid_0's multi_logloss: 0.00271731\n",
            "[15000]\tvalid_0's multi_logloss: 0.00225741\n",
            "[16000]\tvalid_0's multi_logloss: 0.00190348\n",
            "[17000]\tvalid_0's multi_logloss: 0.00172926\n",
            "[18000]\tvalid_0's multi_logloss: 0.001517\n",
            "[19000]\tvalid_0's multi_logloss: 0.00107585\n",
            "[20000]\tvalid_0's multi_logloss: 0.000806115\n",
            "[21000]\tvalid_0's multi_logloss: 0.000602599\n",
            "[22000]\tvalid_0's multi_logloss: 0.000445083\n",
            "[23000]\tvalid_0's multi_logloss: 0.000297681\n",
            "[24000]\tvalid_0's multi_logloss: 0.000232867\n",
            "[25000]\tvalid_0's multi_logloss: 0.000179972\n",
            "[26000]\tvalid_0's multi_logloss: 0.000128015\n",
            "[27000]\tvalid_0's multi_logloss: 9.28792e-05\n",
            "[28000]\tvalid_0's multi_logloss: 7.06373e-05\n",
            "[29000]\tvalid_0's multi_logloss: 5.5141e-05\n",
            "[30000]\tvalid_0's multi_logloss: 4.54553e-05\n",
            "[31000]\tvalid_0's multi_logloss: 3.69644e-05\n",
            "[32000]\tvalid_0's multi_logloss: 2.89297e-05\n",
            "[33000]\tvalid_0's multi_logloss: 2.20906e-05\n",
            "[34000]\tvalid_0's multi_logloss: 1.74966e-05\n",
            "[35000]\tvalid_0's multi_logloss: 1.40851e-05\n",
            "[36000]\tvalid_0's multi_logloss: 1.02379e-05\n",
            "[37000]\tvalid_0's multi_logloss: 7.44081e-06\n",
            "[38000]\tvalid_0's multi_logloss: 5.12851e-06\n",
            "[39000]\tvalid_0's multi_logloss: 3.3464e-06\n",
            "[40000]\tvalid_0's multi_logloss: 2.62029e-06\n",
            "[41000]\tvalid_0's multi_logloss: 2.06947e-06\n",
            "[42000]\tvalid_0's multi_logloss: 1.70208e-06\n",
            "[43000]\tvalid_0's multi_logloss: 1.51735e-06\n",
            "[44000]\tvalid_0's multi_logloss: 1.36695e-06\n",
            "[45000]\tvalid_0's multi_logloss: 1.20605e-06\n",
            "[46000]\tvalid_0's multi_logloss: 1.01897e-06\n",
            "[47000]\tvalid_0's multi_logloss: 8.71854e-07\n",
            "[48000]\tvalid_0's multi_logloss: 7.48399e-07\n",
            "[49000]\tvalid_0's multi_logloss: 6.78936e-07\n",
            "[50000]\tvalid_0's multi_logloss: 6.06261e-07\n",
            "[51000]\tvalid_0's multi_logloss: 5.47965e-07\n",
            "[52000]\tvalid_0's multi_logloss: 4.93843e-07\n",
            "[53000]\tvalid_0's multi_logloss: 4.41473e-07\n",
            "[54000]\tvalid_0's multi_logloss: 4.0128e-07\n",
            "[55000]\tvalid_0's multi_logloss: 3.76285e-07\n",
            "[56000]\tvalid_0's multi_logloss: 3.68446e-07\n",
            "[57000]\tvalid_0's multi_logloss: 3.53484e-07\n",
            "[58000]\tvalid_0's multi_logloss: 3.43527e-07\n",
            "[59000]\tvalid_0's multi_logloss: 3.32027e-07\n",
            "[60000]\tvalid_0's multi_logloss: 3.24716e-07\n",
            "[61000]\tvalid_0's multi_logloss: 3.17778e-07\n",
            "[62000]\tvalid_0's multi_logloss: 3.13559e-07\n",
            "[63000]\tvalid_0's multi_logloss: 3.07685e-07\n",
            "[64000]\tvalid_0's multi_logloss: 3.039e-07\n",
            "[65000]\tvalid_0's multi_logloss: 2.98956e-07\n",
            "[66000]\tvalid_0's multi_logloss: 2.93641e-07\n",
            "[67000]\tvalid_0's multi_logloss: 2.87355e-07\n",
            "[68000]\tvalid_0's multi_logloss: 2.77221e-07\n",
            "[69000]\tvalid_0's multi_logloss: 2.67977e-07\n",
            "[70000]\tvalid_0's multi_logloss: 2.61295e-07\n",
            "[71000]\tvalid_0's multi_logloss: 2.56079e-07\n",
            "[72000]\tvalid_0's multi_logloss: 2.50198e-07\n",
            "[73000]\tvalid_0's multi_logloss: 2.48873e-07\n",
            "[74000]\tvalid_0's multi_logloss: 2.44539e-07\n",
            "[75000]\tvalid_0's multi_logloss: 2.3955e-07\n",
            "[76000]\tvalid_0's multi_logloss: 2.35533e-07\n",
            "[77000]\tvalid_0's multi_logloss: 2.31497e-07\n",
            "[78000]\tvalid_0's multi_logloss: 2.20441e-07\n",
            "[79000]\tvalid_0's multi_logloss: 2.05556e-07\n",
            "[80000]\tvalid_0's multi_logloss: 1.99056e-07\n",
            "[81000]\tvalid_0's multi_logloss: 1.95186e-07\n",
            "[82000]\tvalid_0's multi_logloss: 1.91092e-07\n",
            "[83000]\tvalid_0's multi_logloss: 1.87699e-07\n",
            "[84000]\tvalid_0's multi_logloss: 1.81268e-07\n",
            "[85000]\tvalid_0's multi_logloss: 1.77913e-07\n",
            "[86000]\tvalid_0's multi_logloss: 1.72163e-07\n",
            "[87000]\tvalid_0's multi_logloss: 1.64926e-07\n",
            "[88000]\tvalid_0's multi_logloss: 1.61947e-07\n",
            "[89000]\tvalid_0's multi_logloss: 1.59674e-07\n",
            "[90000]\tvalid_0's multi_logloss: 1.58602e-07\n",
            "[91000]\tvalid_0's multi_logloss: 1.57376e-07\n",
            "[92000]\tvalid_0's multi_logloss: 1.54471e-07\n",
            "[93000]\tvalid_0's multi_logloss: 1.5233e-07\n",
            "[94000]\tvalid_0's multi_logloss: 1.50496e-07\n",
            "[95000]\tvalid_0's multi_logloss: 1.49167e-07\n",
            "[96000]\tvalid_0's multi_logloss: 1.48526e-07\n",
            "[97000]\tvalid_0's multi_logloss: 1.46841e-07\n",
            "[98000]\tvalid_0's multi_logloss: 1.46026e-07\n",
            "[99000]\tvalid_0's multi_logloss: 1.45516e-07\n",
            "[100000]\tvalid_0's multi_logloss: 1.45239e-07\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[99990]\tvalid_0's multi_logloss: 1.45237e-07\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.379002\n",
            "[2000]\tvalid_0's multi_logloss: 0.162525\n",
            "[3000]\tvalid_0's multi_logloss: 0.0737966\n",
            "[4000]\tvalid_0's multi_logloss: 0.0410476\n",
            "[5000]\tvalid_0's multi_logloss: 0.0276673\n",
            "[6000]\tvalid_0's multi_logloss: 0.021075\n",
            "[7000]\tvalid_0's multi_logloss: 0.0168462\n",
            "[8000]\tvalid_0's multi_logloss: 0.0151689\n",
            "[9000]\tvalid_0's multi_logloss: 0.0128299\n",
            "[10000]\tvalid_0's multi_logloss: 0.0129072\n",
            "[11000]\tvalid_0's multi_logloss: 0.0124219\n",
            "[12000]\tvalid_0's multi_logloss: 0.0134859\n",
            "Early stopping, best iteration is:\n",
            "[10780]\tvalid_0's multi_logloss: 0.0123417\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.548361\n",
            "[2000]\tvalid_0's multi_logloss: 0.366878\n",
            "[3000]\tvalid_0's multi_logloss: 0.31053\n",
            "[4000]\tvalid_0's multi_logloss: 0.285488\n",
            "[5000]\tvalid_0's multi_logloss: 0.268702\n",
            "[6000]\tvalid_0's multi_logloss: 0.278121\n",
            "Early stopping, best iteration is:\n",
            "[4668]\tvalid_0's multi_logloss: 0.262757\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.540148\n",
            "[2000]\tvalid_0's multi_logloss: 0.406066\n",
            "[3000]\tvalid_0's multi_logloss: 0.381298\n",
            "[4000]\tvalid_0's multi_logloss: 0.410656\n",
            "Early stopping, best iteration is:\n",
            "[2937]\tvalid_0's multi_logloss: 0.380803\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.680223\n",
            "[2000]\tvalid_0's multi_logloss: 0.558711\n",
            "[3000]\tvalid_0's multi_logloss: 0.50027\n",
            "[4000]\tvalid_0's multi_logloss: 0.489102\n",
            "[5000]\tvalid_0's multi_logloss: 0.505304\n",
            "[6000]\tvalid_0's multi_logloss: 0.49545\n",
            "Early stopping, best iteration is:\n",
            "[4144]\tvalid_0's multi_logloss: 0.484775\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.401874\n",
            "[2000]\tvalid_0's multi_logloss: 0.184339\n",
            "[3000]\tvalid_0's multi_logloss: 0.0972968\n",
            "[4000]\tvalid_0's multi_logloss: 0.0567513\n",
            "[5000]\tvalid_0's multi_logloss: 0.0329761\n",
            "[6000]\tvalid_0's multi_logloss: 0.0235372\n",
            "[7000]\tvalid_0's multi_logloss: 0.017279\n",
            "[8000]\tvalid_0's multi_logloss: 0.0125748\n",
            "[9000]\tvalid_0's multi_logloss: 0.00914715\n",
            "[10000]\tvalid_0's multi_logloss: 0.00737785\n",
            "[11000]\tvalid_0's multi_logloss: 0.0061701\n",
            "[12000]\tvalid_0's multi_logloss: 0.00484267\n",
            "[13000]\tvalid_0's multi_logloss: 0.00420011\n",
            "[14000]\tvalid_0's multi_logloss: 0.00329876\n",
            "[15000]\tvalid_0's multi_logloss: 0.00297663\n",
            "[16000]\tvalid_0's multi_logloss: 0.00255745\n",
            "[17000]\tvalid_0's multi_logloss: 0.00206992\n",
            "[18000]\tvalid_0's multi_logloss: 0.00155418\n",
            "[19000]\tvalid_0's multi_logloss: 0.00115414\n",
            "[20000]\tvalid_0's multi_logloss: 0.000799348\n",
            "[21000]\tvalid_0's multi_logloss: 0.000532392\n",
            "[22000]\tvalid_0's multi_logloss: 0.000389036\n",
            "[23000]\tvalid_0's multi_logloss: 0.000310968\n",
            "[24000]\tvalid_0's multi_logloss: 0.000232007\n",
            "[25000]\tvalid_0's multi_logloss: 0.000176154\n",
            "[26000]\tvalid_0's multi_logloss: 0.000155018\n",
            "[27000]\tvalid_0's multi_logloss: 0.000123084\n",
            "[28000]\tvalid_0's multi_logloss: 8.92689e-05\n",
            "[29000]\tvalid_0's multi_logloss: 5.65689e-05\n",
            "[30000]\tvalid_0's multi_logloss: 3.8848e-05\n",
            "[31000]\tvalid_0's multi_logloss: 3.16681e-05\n",
            "[32000]\tvalid_0's multi_logloss: 2.68673e-05\n",
            "[33000]\tvalid_0's multi_logloss: 2.39279e-05\n",
            "[34000]\tvalid_0's multi_logloss: 1.70578e-05\n",
            "[35000]\tvalid_0's multi_logloss: 1.71712e-05\n",
            "[36000]\tvalid_0's multi_logloss: 1.43456e-05\n",
            "[37000]\tvalid_0's multi_logloss: 1.31973e-05\n",
            "[38000]\tvalid_0's multi_logloss: 1.06351e-05\n",
            "[39000]\tvalid_0's multi_logloss: 9.03398e-06\n",
            "[40000]\tvalid_0's multi_logloss: 7.75565e-06\n",
            "[41000]\tvalid_0's multi_logloss: 6.63202e-06\n",
            "[42000]\tvalid_0's multi_logloss: 6.0375e-06\n",
            "[43000]\tvalid_0's multi_logloss: 5.7689e-06\n",
            "[44000]\tvalid_0's multi_logloss: 5.25754e-06\n",
            "[45000]\tvalid_0's multi_logloss: 4.75235e-06\n",
            "[46000]\tvalid_0's multi_logloss: 4.65273e-06\n",
            "[47000]\tvalid_0's multi_logloss: 5.00082e-06\n",
            "[48000]\tvalid_0's multi_logloss: 5.10766e-06\n",
            "Early stopping, best iteration is:\n",
            "[46024]\tvalid_0's multi_logloss: 4.6514e-06\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.385923\n",
            "[2000]\tvalid_0's multi_logloss: 0.155834\n",
            "[3000]\tvalid_0's multi_logloss: 0.073557\n",
            "[4000]\tvalid_0's multi_logloss: 0.0442929\n",
            "[5000]\tvalid_0's multi_logloss: 0.0285178\n",
            "[6000]\tvalid_0's multi_logloss: 0.0214225\n",
            "[7000]\tvalid_0's multi_logloss: 0.0172275\n",
            "[8000]\tvalid_0's multi_logloss: 0.017452\n",
            "[9000]\tvalid_0's multi_logloss: 0.0172175\n",
            "[10000]\tvalid_0's multi_logloss: 0.0172432\n",
            "[11000]\tvalid_0's multi_logloss: 0.0156199\n",
            "[12000]\tvalid_0's multi_logloss: 0.0157642\n",
            "[13000]\tvalid_0's multi_logloss: 0.0157504\n",
            "Early stopping, best iteration is:\n",
            "[11133]\tvalid_0's multi_logloss: 0.0154171\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.45512\n",
            "[2000]\tvalid_0's multi_logloss: 0.242076\n",
            "[3000]\tvalid_0's multi_logloss: 0.156281\n",
            "[4000]\tvalid_0's multi_logloss: 0.104708\n",
            "[5000]\tvalid_0's multi_logloss: 0.0787952\n",
            "[6000]\tvalid_0's multi_logloss: 0.0592806\n",
            "[7000]\tvalid_0's multi_logloss: 0.0432589\n",
            "[8000]\tvalid_0's multi_logloss: 0.0321184\n",
            "[9000]\tvalid_0's multi_logloss: 0.0268047\n",
            "[10000]\tvalid_0's multi_logloss: 0.0195369\n",
            "[11000]\tvalid_0's multi_logloss: 0.0154684\n",
            "[12000]\tvalid_0's multi_logloss: 0.0118088\n",
            "[13000]\tvalid_0's multi_logloss: 0.0117275\n",
            "[14000]\tvalid_0's multi_logloss: 0.0113512\n",
            "[15000]\tvalid_0's multi_logloss: 0.00941954\n",
            "[16000]\tvalid_0's multi_logloss: 0.00661011\n",
            "[17000]\tvalid_0's multi_logloss: 0.00473822\n",
            "[18000]\tvalid_0's multi_logloss: 0.00382765\n",
            "[19000]\tvalid_0's multi_logloss: 0.0032008\n",
            "[20000]\tvalid_0's multi_logloss: 0.00255499\n",
            "[21000]\tvalid_0's multi_logloss: 0.00216613\n",
            "[22000]\tvalid_0's multi_logloss: 0.00190082\n",
            "[23000]\tvalid_0's multi_logloss: 0.00190564\n",
            "[24000]\tvalid_0's multi_logloss: 0.00149827\n",
            "[25000]\tvalid_0's multi_logloss: 0.00119953\n",
            "[26000]\tvalid_0's multi_logloss: 0.00108233\n",
            "[27000]\tvalid_0's multi_logloss: 0.00109086\n",
            "[28000]\tvalid_0's multi_logloss: 0.000920562\n",
            "[29000]\tvalid_0's multi_logloss: 0.000704425\n",
            "[30000]\tvalid_0's multi_logloss: 0.0005075\n",
            "[31000]\tvalid_0's multi_logloss: 0.000519765\n",
            "[32000]\tvalid_0's multi_logloss: 0.000502353\n",
            "[33000]\tvalid_0's multi_logloss: 0.00033524\n",
            "[34000]\tvalid_0's multi_logloss: 0.000250959\n",
            "[35000]\tvalid_0's multi_logloss: 0.000226231\n",
            "[36000]\tvalid_0's multi_logloss: 0.000201222\n",
            "[37000]\tvalid_0's multi_logloss: 0.000161681\n",
            "[38000]\tvalid_0's multi_logloss: 0.000133715\n",
            "[39000]\tvalid_0's multi_logloss: 0.0001078\n",
            "[40000]\tvalid_0's multi_logloss: 9.69931e-05\n",
            "[41000]\tvalid_0's multi_logloss: 8.67874e-05\n",
            "[42000]\tvalid_0's multi_logloss: 7.94414e-05\n",
            "[43000]\tvalid_0's multi_logloss: 7.39215e-05\n",
            "[44000]\tvalid_0's multi_logloss: 6.95705e-05\n",
            "[45000]\tvalid_0's multi_logloss: 6.93332e-05\n",
            "[46000]\tvalid_0's multi_logloss: 6.50415e-05\n",
            "[47000]\tvalid_0's multi_logloss: 6.67051e-05\n",
            "[48000]\tvalid_0's multi_logloss: 6.70289e-05\n",
            "Early stopping, best iteration is:\n",
            "[46116]\tvalid_0's multi_logloss: 6.47638e-05\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.56921\n",
            "[2000]\tvalid_0's multi_logloss: 0.377591\n",
            "[3000]\tvalid_0's multi_logloss: 0.306847\n",
            "[4000]\tvalid_0's multi_logloss: 0.297558\n",
            "[5000]\tvalid_0's multi_logloss: 0.315457\n",
            "Early stopping, best iteration is:\n",
            "[3702]\tvalid_0's multi_logloss: 0.293062\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.379943\n",
            "[2000]\tvalid_0's multi_logloss: 0.167486\n",
            "[3000]\tvalid_0's multi_logloss: 0.0869182\n",
            "[4000]\tvalid_0's multi_logloss: 0.0469987\n",
            "[5000]\tvalid_0's multi_logloss: 0.0268746\n",
            "[6000]\tvalid_0's multi_logloss: 0.0162959\n",
            "[7000]\tvalid_0's multi_logloss: 0.00929476\n",
            "[8000]\tvalid_0's multi_logloss: 0.00545127\n",
            "[9000]\tvalid_0's multi_logloss: 0.00380867\n",
            "[10000]\tvalid_0's multi_logloss: 0.00232191\n",
            "[11000]\tvalid_0's multi_logloss: 0.00149048\n",
            "[12000]\tvalid_0's multi_logloss: 0.000989705\n",
            "[13000]\tvalid_0's multi_logloss: 0.00067845\n",
            "[14000]\tvalid_0's multi_logloss: 0.000504826\n",
            "[15000]\tvalid_0's multi_logloss: 0.000409388\n",
            "[16000]\tvalid_0's multi_logloss: 0.000324234\n",
            "[17000]\tvalid_0's multi_logloss: 0.000184323\n",
            "[18000]\tvalid_0's multi_logloss: 0.000104682\n",
            "[19000]\tvalid_0's multi_logloss: 6.43541e-05\n",
            "[20000]\tvalid_0's multi_logloss: 4.53272e-05\n",
            "[21000]\tvalid_0's multi_logloss: 3.41247e-05\n",
            "[22000]\tvalid_0's multi_logloss: 2.95395e-05\n",
            "[23000]\tvalid_0's multi_logloss: 2.80049e-05\n",
            "[24000]\tvalid_0's multi_logloss: 2.20528e-05\n",
            "[25000]\tvalid_0's multi_logloss: 2.31641e-05\n",
            "[26000]\tvalid_0's multi_logloss: 1.90477e-05\n",
            "[27000]\tvalid_0's multi_logloss: 1.9988e-05\n",
            "[28000]\tvalid_0's multi_logloss: 1.9005e-05\n",
            "[29000]\tvalid_0's multi_logloss: 1.78779e-05\n",
            "[30000]\tvalid_0's multi_logloss: 1.67693e-05\n",
            "[31000]\tvalid_0's multi_logloss: 1.96867e-05\n",
            "[32000]\tvalid_0's multi_logloss: 1.55506e-05\n",
            "[33000]\tvalid_0's multi_logloss: 1.55787e-05\n",
            "[34000]\tvalid_0's multi_logloss: 1.72758e-05\n",
            "Early stopping, best iteration is:\n",
            "[32392]\tvalid_0's multi_logloss: 1.47555e-05\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.517097\n",
            "[2000]\tvalid_0's multi_logloss: 0.265346\n",
            "[3000]\tvalid_0's multi_logloss: 0.149208\n",
            "[4000]\tvalid_0's multi_logloss: 0.0902971\n",
            "[5000]\tvalid_0's multi_logloss: 0.0544254\n",
            "[6000]\tvalid_0's multi_logloss: 0.0334078\n",
            "[7000]\tvalid_0's multi_logloss: 0.0223354\n",
            "[8000]\tvalid_0's multi_logloss: 0.0199669\n",
            "[9000]\tvalid_0's multi_logloss: 0.0175079\n",
            "[10000]\tvalid_0's multi_logloss: 0.0167842\n",
            "[11000]\tvalid_0's multi_logloss: 0.0145631\n",
            "[12000]\tvalid_0's multi_logloss: 0.0137441\n",
            "[13000]\tvalid_0's multi_logloss: 0.0122655\n",
            "[14000]\tvalid_0's multi_logloss: 0.0105381\n",
            "[15000]\tvalid_0's multi_logloss: 0.00886896\n",
            "[16000]\tvalid_0's multi_logloss: 0.00767684\n",
            "[17000]\tvalid_0's multi_logloss: 0.00712617\n",
            "[18000]\tvalid_0's multi_logloss: 0.00661503\n",
            "[19000]\tvalid_0's multi_logloss: 0.00547762\n",
            "[20000]\tvalid_0's multi_logloss: 0.00461962\n",
            "[21000]\tvalid_0's multi_logloss: 0.00406948\n",
            "[22000]\tvalid_0's multi_logloss: 0.00357932\n",
            "[23000]\tvalid_0's multi_logloss: 0.00317363\n",
            "[24000]\tvalid_0's multi_logloss: 0.00273658\n",
            "[25000]\tvalid_0's multi_logloss: 0.00200695\n",
            "[26000]\tvalid_0's multi_logloss: 0.00167954\n",
            "[27000]\tvalid_0's multi_logloss: 0.00150336\n",
            "[28000]\tvalid_0's multi_logloss: 0.00109582\n",
            "[29000]\tvalid_0's multi_logloss: 0.000830754\n",
            "[30000]\tvalid_0's multi_logloss: 0.000800234\n",
            "[31000]\tvalid_0's multi_logloss: 0.000705847\n",
            "[32000]\tvalid_0's multi_logloss: 0.000643617\n",
            "[33000]\tvalid_0's multi_logloss: 0.000704541\n",
            "[34000]\tvalid_0's multi_logloss: 0.000748836\n",
            "Early stopping, best iteration is:\n",
            "[32382]\tvalid_0's multi_logloss: 0.000629684\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.629844\n",
            "[2000]\tvalid_0's multi_logloss: 0.346687\n",
            "[3000]\tvalid_0's multi_logloss: 0.256997\n",
            "[4000]\tvalid_0's multi_logloss: 0.194122\n",
            "[5000]\tvalid_0's multi_logloss: 0.17575\n",
            "[6000]\tvalid_0's multi_logloss: 0.172701\n",
            "[7000]\tvalid_0's multi_logloss: 0.165113\n",
            "[8000]\tvalid_0's multi_logloss: 0.174011\n",
            "[9000]\tvalid_0's multi_logloss: 0.134767\n",
            "[10000]\tvalid_0's multi_logloss: 0.124596\n",
            "[11000]\tvalid_0's multi_logloss: 0.110233\n",
            "[12000]\tvalid_0's multi_logloss: 0.104315\n",
            "[13000]\tvalid_0's multi_logloss: 0.0972508\n",
            "[14000]\tvalid_0's multi_logloss: 0.0869437\n",
            "[15000]\tvalid_0's multi_logloss: 0.0690255\n",
            "[16000]\tvalid_0's multi_logloss: 0.0569582\n",
            "[17000]\tvalid_0's multi_logloss: 0.0437397\n",
            "[18000]\tvalid_0's multi_logloss: 0.0403146\n",
            "[19000]\tvalid_0's multi_logloss: 0.0395913\n",
            "[20000]\tvalid_0's multi_logloss: 0.0334735\n",
            "[21000]\tvalid_0's multi_logloss: 0.0210528\n",
            "[22000]\tvalid_0's multi_logloss: 0.0144963\n",
            "[23000]\tvalid_0's multi_logloss: 0.012087\n",
            "[24000]\tvalid_0's multi_logloss: 0.0109866\n",
            "[25000]\tvalid_0's multi_logloss: 0.0106256\n",
            "[26000]\tvalid_0's multi_logloss: 0.010127\n",
            "Early stopping, best iteration is:\n",
            "[24330]\tvalid_0's multi_logloss: 0.00999579\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.544632\n",
            "[2000]\tvalid_0's multi_logloss: 0.309691\n",
            "[3000]\tvalid_0's multi_logloss: 0.219627\n",
            "[4000]\tvalid_0's multi_logloss: 0.188064\n",
            "[5000]\tvalid_0's multi_logloss: 0.156021\n",
            "[6000]\tvalid_0's multi_logloss: 0.143796\n",
            "[7000]\tvalid_0's multi_logloss: 0.126505\n",
            "[8000]\tvalid_0's multi_logloss: 0.105361\n",
            "[9000]\tvalid_0's multi_logloss: 0.106445\n",
            "[10000]\tvalid_0's multi_logloss: 0.108422\n",
            "[11000]\tvalid_0's multi_logloss: 0.0977243\n",
            "[12000]\tvalid_0's multi_logloss: 0.0801292\n",
            "[13000]\tvalid_0's multi_logloss: 0.0618346\n",
            "[14000]\tvalid_0's multi_logloss: 0.054474\n",
            "[15000]\tvalid_0's multi_logloss: 0.0477279\n",
            "[16000]\tvalid_0's multi_logloss: 0.0434439\n",
            "[17000]\tvalid_0's multi_logloss: 0.0392152\n",
            "[18000]\tvalid_0's multi_logloss: 0.0345028\n",
            "[19000]\tvalid_0's multi_logloss: 0.0304143\n",
            "[20000]\tvalid_0's multi_logloss: 0.027034\n",
            "[21000]\tvalid_0's multi_logloss: 0.0235533\n",
            "[22000]\tvalid_0's multi_logloss: 0.0206873\n",
            "[23000]\tvalid_0's multi_logloss: 0.0179573\n",
            "[24000]\tvalid_0's multi_logloss: 0.01591\n",
            "[25000]\tvalid_0's multi_logloss: 0.0139819\n",
            "[26000]\tvalid_0's multi_logloss: 0.0131401\n",
            "[27000]\tvalid_0's multi_logloss: 0.014222\n",
            "[28000]\tvalid_0's multi_logloss: 0.0117595\n",
            "[29000]\tvalid_0's multi_logloss: 0.0101964\n",
            "[30000]\tvalid_0's multi_logloss: 0.00983789\n",
            "[31000]\tvalid_0's multi_logloss: 0.00925419\n",
            "[32000]\tvalid_0's multi_logloss: 0.00931649\n",
            "[33000]\tvalid_0's multi_logloss: 0.00886646\n",
            "[34000]\tvalid_0's multi_logloss: 0.00769562\n",
            "[35000]\tvalid_0's multi_logloss: 0.00742686\n",
            "[36000]\tvalid_0's multi_logloss: 0.00616677\n",
            "[37000]\tvalid_0's multi_logloss: 0.00545428\n",
            "[38000]\tvalid_0's multi_logloss: 0.0047823\n",
            "[39000]\tvalid_0's multi_logloss: 0.00442055\n",
            "[40000]\tvalid_0's multi_logloss: 0.00407101\n",
            "[41000]\tvalid_0's multi_logloss: 0.0042018\n",
            "Early stopping, best iteration is:\n",
            "[39949]\tvalid_0's multi_logloss: 0.00405777\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.539269\n",
            "[2000]\tvalid_0's multi_logloss: 0.349178\n",
            "[3000]\tvalid_0's multi_logloss: 0.305244\n",
            "[4000]\tvalid_0's multi_logloss: 0.256519\n",
            "[5000]\tvalid_0's multi_logloss: 0.224056\n",
            "[6000]\tvalid_0's multi_logloss: 0.184738\n",
            "[7000]\tvalid_0's multi_logloss: 0.169072\n",
            "[8000]\tvalid_0's multi_logloss: 0.162528\n",
            "[9000]\tvalid_0's multi_logloss: 0.144279\n",
            "[10000]\tvalid_0's multi_logloss: 0.133171\n",
            "[11000]\tvalid_0's multi_logloss: 0.116778\n",
            "[12000]\tvalid_0's multi_logloss: 0.0837356\n",
            "[13000]\tvalid_0's multi_logloss: 0.0702834\n",
            "[14000]\tvalid_0's multi_logloss: 0.0637651\n",
            "[15000]\tvalid_0's multi_logloss: 0.0511937\n",
            "[16000]\tvalid_0's multi_logloss: 0.0450886\n",
            "[17000]\tvalid_0's multi_logloss: 0.040777\n",
            "[18000]\tvalid_0's multi_logloss: 0.0408499\n",
            "[19000]\tvalid_0's multi_logloss: 0.0328889\n",
            "[20000]\tvalid_0's multi_logloss: 0.0280607\n",
            "[21000]\tvalid_0's multi_logloss: 0.0281343\n",
            "[22000]\tvalid_0's multi_logloss: 0.0252225\n",
            "[23000]\tvalid_0's multi_logloss: 0.0255965\n",
            "Early stopping, best iteration is:\n",
            "[21620]\tvalid_0's multi_logloss: 0.0245317\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.681987\n",
            "[2000]\tvalid_0's multi_logloss: 0.505216\n",
            "[3000]\tvalid_0's multi_logloss: 0.364397\n",
            "[4000]\tvalid_0's multi_logloss: 0.286731\n",
            "[5000]\tvalid_0's multi_logloss: 0.178817\n",
            "[6000]\tvalid_0's multi_logloss: 0.113409\n",
            "[7000]\tvalid_0's multi_logloss: 0.0904903\n",
            "[8000]\tvalid_0's multi_logloss: 0.0784843\n",
            "[9000]\tvalid_0's multi_logloss: 0.0686562\n",
            "[10000]\tvalid_0's multi_logloss: 0.0580241\n",
            "[11000]\tvalid_0's multi_logloss: 0.0522559\n",
            "[12000]\tvalid_0's multi_logloss: 0.048018\n",
            "[13000]\tvalid_0's multi_logloss: 0.0389737\n",
            "[14000]\tvalid_0's multi_logloss: 0.0293138\n",
            "[15000]\tvalid_0's multi_logloss: 0.0233226\n",
            "[16000]\tvalid_0's multi_logloss: 0.0204265\n",
            "[17000]\tvalid_0's multi_logloss: 0.0176769\n",
            "[18000]\tvalid_0's multi_logloss: 0.0135148\n",
            "[19000]\tvalid_0's multi_logloss: 0.00990437\n",
            "[20000]\tvalid_0's multi_logloss: 0.0076625\n",
            "[21000]\tvalid_0's multi_logloss: 0.00596358\n",
            "[22000]\tvalid_0's multi_logloss: 0.00477409\n",
            "[23000]\tvalid_0's multi_logloss: 0.00367588\n",
            "[24000]\tvalid_0's multi_logloss: 0.00290762\n",
            "[25000]\tvalid_0's multi_logloss: 0.00237094\n",
            "[26000]\tvalid_0's multi_logloss: 0.00200207\n",
            "[27000]\tvalid_0's multi_logloss: 0.00179124\n",
            "[28000]\tvalid_0's multi_logloss: 0.00131766\n",
            "[29000]\tvalid_0's multi_logloss: 0.000968825\n",
            "[30000]\tvalid_0's multi_logloss: 0.000713269\n",
            "[31000]\tvalid_0's multi_logloss: 0.000595271\n",
            "[32000]\tvalid_0's multi_logloss: 0.000584827\n",
            "[33000]\tvalid_0's multi_logloss: 0.000524558\n",
            "[34000]\tvalid_0's multi_logloss: 0.000379646\n",
            "[35000]\tvalid_0's multi_logloss: 0.00030386\n",
            "[36000]\tvalid_0's multi_logloss: 0.000232869\n",
            "[37000]\tvalid_0's multi_logloss: 0.000207252\n",
            "[38000]\tvalid_0's multi_logloss: 0.0001807\n",
            "[39000]\tvalid_0's multi_logloss: 0.000154895\n",
            "[40000]\tvalid_0's multi_logloss: 0.000158807\n",
            "[41000]\tvalid_0's multi_logloss: 0.000181302\n",
            "Early stopping, best iteration is:\n",
            "[39205]\tvalid_0's multi_logloss: 0.000152654\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.723235\n",
            "[2000]\tvalid_0's multi_logloss: 0.503357\n",
            "[3000]\tvalid_0's multi_logloss: 0.429944\n",
            "[4000]\tvalid_0's multi_logloss: 0.425432\n",
            "[5000]\tvalid_0's multi_logloss: 0.462746\n",
            "Early stopping, best iteration is:\n",
            "[3492]\tvalid_0's multi_logloss: 0.420949\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.471648\n",
            "[2000]\tvalid_0's multi_logloss: 0.210399\n",
            "[3000]\tvalid_0's multi_logloss: 0.121971\n",
            "[4000]\tvalid_0's multi_logloss: 0.0884264\n",
            "[5000]\tvalid_0's multi_logloss: 0.0698938\n",
            "[6000]\tvalid_0's multi_logloss: 0.0640491\n",
            "[7000]\tvalid_0's multi_logloss: 0.0675689\n",
            "[8000]\tvalid_0's multi_logloss: 0.0528794\n",
            "[9000]\tvalid_0's multi_logloss: 0.0422774\n",
            "[10000]\tvalid_0's multi_logloss: 0.0332762\n",
            "[11000]\tvalid_0's multi_logloss: 0.026275\n",
            "[12000]\tvalid_0's multi_logloss: 0.0199167\n",
            "[13000]\tvalid_0's multi_logloss: 0.0171022\n",
            "[14000]\tvalid_0's multi_logloss: 0.0150147\n",
            "[15000]\tvalid_0's multi_logloss: 0.0124002\n",
            "[16000]\tvalid_0's multi_logloss: 0.0103472\n",
            "[17000]\tvalid_0's multi_logloss: 0.00868987\n",
            "[18000]\tvalid_0's multi_logloss: 0.00745307\n",
            "[19000]\tvalid_0's multi_logloss: 0.00711248\n",
            "[20000]\tvalid_0's multi_logloss: 0.00717377\n",
            "[21000]\tvalid_0's multi_logloss: 0.00686592\n",
            "[22000]\tvalid_0's multi_logloss: 0.00662573\n",
            "[23000]\tvalid_0's multi_logloss: 0.00669351\n",
            "[24000]\tvalid_0's multi_logloss: 0.0075998\n",
            "Early stopping, best iteration is:\n",
            "[22280]\tvalid_0's multi_logloss: 0.00646611\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.603818\n",
            "[2000]\tvalid_0's multi_logloss: 0.484602\n",
            "[3000]\tvalid_0's multi_logloss: 0.484238\n",
            "[4000]\tvalid_0's multi_logloss: 0.525218\n",
            "Early stopping, best iteration is:\n",
            "[2443]\tvalid_0's multi_logloss: 0.47496\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.711499\n",
            "[2000]\tvalid_0's multi_logloss: 0.510334\n",
            "[3000]\tvalid_0's multi_logloss: 0.330914\n",
            "[4000]\tvalid_0's multi_logloss: 0.213982\n",
            "[5000]\tvalid_0's multi_logloss: 0.13783\n",
            "[6000]\tvalid_0's multi_logloss: 0.0880634\n",
            "[7000]\tvalid_0's multi_logloss: 0.0593755\n",
            "[8000]\tvalid_0's multi_logloss: 0.0407815\n",
            "[9000]\tvalid_0's multi_logloss: 0.0315461\n",
            "[10000]\tvalid_0's multi_logloss: 0.0251157\n",
            "[11000]\tvalid_0's multi_logloss: 0.0194445\n",
            "[12000]\tvalid_0's multi_logloss: 0.0191706\n",
            "[13000]\tvalid_0's multi_logloss: 0.019535\n",
            "[14000]\tvalid_0's multi_logloss: 0.0173333\n",
            "[15000]\tvalid_0's multi_logloss: 0.0149611\n",
            "[16000]\tvalid_0's multi_logloss: 0.0123769\n",
            "[17000]\tvalid_0's multi_logloss: 0.0102962\n",
            "[18000]\tvalid_0's multi_logloss: 0.00810979\n",
            "[19000]\tvalid_0's multi_logloss: 0.00782957\n",
            "[20000]\tvalid_0's multi_logloss: 0.00639841\n",
            "[21000]\tvalid_0's multi_logloss: 0.00453942\n",
            "[22000]\tvalid_0's multi_logloss: 0.00355128\n",
            "[23000]\tvalid_0's multi_logloss: 0.00300444\n",
            "[24000]\tvalid_0's multi_logloss: 0.00258464\n",
            "[25000]\tvalid_0's multi_logloss: 0.00218203\n",
            "[26000]\tvalid_0's multi_logloss: 0.00182604\n",
            "[27000]\tvalid_0's multi_logloss: 0.00148164\n",
            "[28000]\tvalid_0's multi_logloss: 0.00121739\n",
            "[29000]\tvalid_0's multi_logloss: 0.000988631\n",
            "[30000]\tvalid_0's multi_logloss: 0.000722909\n",
            "[31000]\tvalid_0's multi_logloss: 0.000528589\n",
            "[32000]\tvalid_0's multi_logloss: 0.000393125\n",
            "[33000]\tvalid_0's multi_logloss: 0.000320491\n",
            "[34000]\tvalid_0's multi_logloss: 0.000327353\n",
            "[35000]\tvalid_0's multi_logloss: 0.000311658\n",
            "[36000]\tvalid_0's multi_logloss: 0.000264477\n",
            "[37000]\tvalid_0's multi_logloss: 0.000205902\n",
            "[38000]\tvalid_0's multi_logloss: 0.000176786\n",
            "[39000]\tvalid_0's multi_logloss: 0.000162091\n",
            "[40000]\tvalid_0's multi_logloss: 0.000141874\n",
            "[41000]\tvalid_0's multi_logloss: 0.000133382\n",
            "[42000]\tvalid_0's multi_logloss: 0.000129576\n",
            "[43000]\tvalid_0's multi_logloss: 0.000117567\n",
            "[44000]\tvalid_0's multi_logloss: 0.000111303\n",
            "[45000]\tvalid_0's multi_logloss: 0.000111167\n",
            "[46000]\tvalid_0's multi_logloss: 0.000113055\n",
            "Early stopping, best iteration is:\n",
            "[44357]\tvalid_0's multi_logloss: 0.000108662\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.529449\n",
            "[2000]\tvalid_0's multi_logloss: 0.478158\n",
            "[3000]\tvalid_0's multi_logloss: 0.476914\n",
            "[4000]\tvalid_0's multi_logloss: 0.516895\n",
            "Early stopping, best iteration is:\n",
            "[2601]\tvalid_0's multi_logloss: 0.471532\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.377607\n",
            "[2000]\tvalid_0's multi_logloss: 0.175017\n",
            "[3000]\tvalid_0's multi_logloss: 0.103352\n",
            "[4000]\tvalid_0's multi_logloss: 0.0650548\n",
            "[5000]\tvalid_0's multi_logloss: 0.0516514\n",
            "[6000]\tvalid_0's multi_logloss: 0.0428479\n",
            "[7000]\tvalid_0's multi_logloss: 0.0267891\n",
            "[8000]\tvalid_0's multi_logloss: 0.0183587\n",
            "[9000]\tvalid_0's multi_logloss: 0.0141029\n",
            "[10000]\tvalid_0's multi_logloss: 0.0103476\n",
            "[11000]\tvalid_0's multi_logloss: 0.00830027\n",
            "[12000]\tvalid_0's multi_logloss: 0.00629418\n",
            "[13000]\tvalid_0's multi_logloss: 0.00496773\n",
            "[14000]\tvalid_0's multi_logloss: 0.00380927\n",
            "[15000]\tvalid_0's multi_logloss: 0.00300185\n",
            "[16000]\tvalid_0's multi_logloss: 0.00243311\n",
            "[17000]\tvalid_0's multi_logloss: 0.00203054\n",
            "[18000]\tvalid_0's multi_logloss: 0.00178541\n",
            "[19000]\tvalid_0's multi_logloss: 0.00167426\n",
            "[20000]\tvalid_0's multi_logloss: 0.00159405\n",
            "[21000]\tvalid_0's multi_logloss: 0.00144689\n",
            "[22000]\tvalid_0's multi_logloss: 0.00120132\n",
            "[23000]\tvalid_0's multi_logloss: 0.000981793\n",
            "[24000]\tvalid_0's multi_logloss: 0.000826391\n",
            "[25000]\tvalid_0's multi_logloss: 0.000682374\n",
            "[26000]\tvalid_0's multi_logloss: 0.000493971\n",
            "[27000]\tvalid_0's multi_logloss: 0.000337657\n",
            "[28000]\tvalid_0's multi_logloss: 0.000240431\n",
            "[29000]\tvalid_0's multi_logloss: 0.000176336\n",
            "[30000]\tvalid_0's multi_logloss: 0.000125976\n",
            "[31000]\tvalid_0's multi_logloss: 9.33917e-05\n",
            "[32000]\tvalid_0's multi_logloss: 6.77311e-05\n",
            "[33000]\tvalid_0's multi_logloss: 4.93258e-05\n",
            "[34000]\tvalid_0's multi_logloss: 3.68476e-05\n",
            "[35000]\tvalid_0's multi_logloss: 2.55751e-05\n",
            "[36000]\tvalid_0's multi_logloss: 2.20459e-05\n",
            "[37000]\tvalid_0's multi_logloss: 1.81875e-05\n",
            "[38000]\tvalid_0's multi_logloss: 1.39401e-05\n",
            "[39000]\tvalid_0's multi_logloss: 9.83447e-06\n",
            "[40000]\tvalid_0's multi_logloss: 8.40673e-06\n",
            "[41000]\tvalid_0's multi_logloss: 7.76761e-06\n",
            "[42000]\tvalid_0's multi_logloss: 6.41839e-06\n",
            "[43000]\tvalid_0's multi_logloss: 5.56131e-06\n",
            "[44000]\tvalid_0's multi_logloss: 5.28381e-06\n",
            "[45000]\tvalid_0's multi_logloss: 4.63745e-06\n",
            "[46000]\tvalid_0's multi_logloss: 3.86678e-06\n",
            "[47000]\tvalid_0's multi_logloss: 3.0293e-06\n",
            "[48000]\tvalid_0's multi_logloss: 2.8038e-06\n",
            "[49000]\tvalid_0's multi_logloss: 2.53957e-06\n",
            "[50000]\tvalid_0's multi_logloss: 2.19868e-06\n",
            "[51000]\tvalid_0's multi_logloss: 1.97038e-06\n",
            "[52000]\tvalid_0's multi_logloss: 1.80852e-06\n",
            "[53000]\tvalid_0's multi_logloss: 1.67553e-06\n",
            "[54000]\tvalid_0's multi_logloss: 1.56378e-06\n",
            "[55000]\tvalid_0's multi_logloss: 1.45441e-06\n",
            "[56000]\tvalid_0's multi_logloss: 1.33213e-06\n",
            "[57000]\tvalid_0's multi_logloss: 1.26572e-06\n",
            "[58000]\tvalid_0's multi_logloss: 1.21514e-06\n",
            "[59000]\tvalid_0's multi_logloss: 1.15693e-06\n",
            "[60000]\tvalid_0's multi_logloss: 1.10548e-06\n",
            "[61000]\tvalid_0's multi_logloss: 1.05775e-06\n",
            "[62000]\tvalid_0's multi_logloss: 1.03352e-06\n",
            "[63000]\tvalid_0's multi_logloss: 9.77851e-07\n",
            "[64000]\tvalid_0's multi_logloss: 9.64739e-07\n",
            "[65000]\tvalid_0's multi_logloss: 9.65015e-07\n",
            "Early stopping, best iteration is:\n",
            "[63387]\tvalid_0's multi_logloss: 9.61849e-07\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.481601\n",
            "[2000]\tvalid_0's multi_logloss: 0.261264\n",
            "[3000]\tvalid_0's multi_logloss: 0.168087\n",
            "[4000]\tvalid_0's multi_logloss: 0.131782\n",
            "[5000]\tvalid_0's multi_logloss: 0.100166\n",
            "[6000]\tvalid_0's multi_logloss: 0.0827233\n",
            "[7000]\tvalid_0's multi_logloss: 0.0662484\n",
            "[8000]\tvalid_0's multi_logloss: 0.0540239\n",
            "[9000]\tvalid_0's multi_logloss: 0.0411533\n",
            "[10000]\tvalid_0's multi_logloss: 0.0348857\n",
            "[11000]\tvalid_0's multi_logloss: 0.027633\n",
            "[12000]\tvalid_0's multi_logloss: 0.0217234\n",
            "[13000]\tvalid_0's multi_logloss: 0.0178546\n",
            "[14000]\tvalid_0's multi_logloss: 0.0158122\n",
            "[15000]\tvalid_0's multi_logloss: 0.0141543\n",
            "[16000]\tvalid_0's multi_logloss: 0.0140027\n",
            "[17000]\tvalid_0's multi_logloss: 0.0119365\n",
            "[18000]\tvalid_0's multi_logloss: 0.0100966\n",
            "[19000]\tvalid_0's multi_logloss: 0.00882632\n",
            "[20000]\tvalid_0's multi_logloss: 0.00710659\n",
            "[21000]\tvalid_0's multi_logloss: 0.00560181\n",
            "[22000]\tvalid_0's multi_logloss: 0.00505964\n",
            "[23000]\tvalid_0's multi_logloss: 0.00426358\n",
            "[24000]\tvalid_0's multi_logloss: 0.0036128\n",
            "[25000]\tvalid_0's multi_logloss: 0.00338826\n",
            "[26000]\tvalid_0's multi_logloss: 0.00311169\n",
            "[27000]\tvalid_0's multi_logloss: 0.00296773\n",
            "[28000]\tvalid_0's multi_logloss: 0.00307552\n",
            "Early stopping, best iteration is:\n",
            "[26671]\tvalid_0's multi_logloss: 0.00284913\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.531387\n",
            "[2000]\tvalid_0's multi_logloss: 0.261043\n",
            "[3000]\tvalid_0's multi_logloss: 0.140403\n",
            "[4000]\tvalid_0's multi_logloss: 0.0841973\n",
            "[5000]\tvalid_0's multi_logloss: 0.0620298\n",
            "[6000]\tvalid_0's multi_logloss: 0.0413155\n",
            "[7000]\tvalid_0's multi_logloss: 0.0319938\n",
            "[8000]\tvalid_0's multi_logloss: 0.0208548\n",
            "[9000]\tvalid_0's multi_logloss: 0.015461\n",
            "[10000]\tvalid_0's multi_logloss: 0.0125903\n",
            "[11000]\tvalid_0's multi_logloss: 0.00945002\n",
            "[12000]\tvalid_0's multi_logloss: 0.00664266\n",
            "[13000]\tvalid_0's multi_logloss: 0.00440183\n",
            "[14000]\tvalid_0's multi_logloss: 0.00286146\n",
            "[15000]\tvalid_0's multi_logloss: 0.00194873\n",
            "[16000]\tvalid_0's multi_logloss: 0.0015842\n",
            "[17000]\tvalid_0's multi_logloss: 0.00140916\n",
            "[18000]\tvalid_0's multi_logloss: 0.00115973\n",
            "[19000]\tvalid_0's multi_logloss: 0.00111796\n",
            "[20000]\tvalid_0's multi_logloss: 0.00120444\n",
            "Early stopping, best iteration is:\n",
            "[18901]\tvalid_0's multi_logloss: 0.00110509\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.514969\n",
            "[2000]\tvalid_0's multi_logloss: 0.330693\n",
            "[3000]\tvalid_0's multi_logloss: 0.228854\n",
            "[4000]\tvalid_0's multi_logloss: 0.186116\n",
            "[5000]\tvalid_0's multi_logloss: 0.190318\n",
            "[6000]\tvalid_0's multi_logloss: 0.203579\n",
            "Early stopping, best iteration is:\n",
            "[4336]\tvalid_0's multi_logloss: 0.183628\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.366393\n",
            "[2000]\tvalid_0's multi_logloss: 0.132261\n",
            "[3000]\tvalid_0's multi_logloss: 0.0537064\n",
            "[4000]\tvalid_0's multi_logloss: 0.0257599\n",
            "[5000]\tvalid_0's multi_logloss: 0.0129256\n",
            "[6000]\tvalid_0's multi_logloss: 0.00693832\n",
            "[7000]\tvalid_0's multi_logloss: 0.00380672\n",
            "[8000]\tvalid_0's multi_logloss: 0.00231944\n",
            "[9000]\tvalid_0's multi_logloss: 0.00153068\n",
            "[10000]\tvalid_0's multi_logloss: 0.000875141\n",
            "[11000]\tvalid_0's multi_logloss: 0.000528895\n",
            "[12000]\tvalid_0's multi_logloss: 0.00034491\n",
            "[13000]\tvalid_0's multi_logloss: 0.000232962\n",
            "[14000]\tvalid_0's multi_logloss: 0.000162426\n",
            "[15000]\tvalid_0's multi_logloss: 0.000104515\n",
            "[16000]\tvalid_0's multi_logloss: 6.80463e-05\n",
            "[17000]\tvalid_0's multi_logloss: 4.11521e-05\n",
            "[18000]\tvalid_0's multi_logloss: 2.61758e-05\n",
            "[19000]\tvalid_0's multi_logloss: 1.61197e-05\n",
            "[20000]\tvalid_0's multi_logloss: 1.05112e-05\n",
            "[21000]\tvalid_0's multi_logloss: 6.82678e-06\n",
            "[22000]\tvalid_0's multi_logloss: 4.21114e-06\n",
            "[23000]\tvalid_0's multi_logloss: 2.66798e-06\n",
            "[24000]\tvalid_0's multi_logloss: 1.61614e-06\n",
            "[25000]\tvalid_0's multi_logloss: 1.03047e-06\n",
            "[26000]\tvalid_0's multi_logloss: 6.74623e-07\n",
            "[27000]\tvalid_0's multi_logloss: 4.83388e-07\n",
            "[28000]\tvalid_0's multi_logloss: 3.62739e-07\n",
            "[29000]\tvalid_0's multi_logloss: 3.03941e-07\n",
            "[30000]\tvalid_0's multi_logloss: 2.51537e-07\n",
            "[31000]\tvalid_0's multi_logloss: 2.32225e-07\n",
            "[32000]\tvalid_0's multi_logloss: 2.05392e-07\n",
            "[33000]\tvalid_0's multi_logloss: 1.80308e-07\n",
            "[34000]\tvalid_0's multi_logloss: 1.55448e-07\n",
            "[35000]\tvalid_0's multi_logloss: 1.38245e-07\n",
            "[36000]\tvalid_0's multi_logloss: 1.28807e-07\n",
            "[37000]\tvalid_0's multi_logloss: 1.19343e-07\n",
            "[38000]\tvalid_0's multi_logloss: 1.11841e-07\n",
            "[39000]\tvalid_0's multi_logloss: 1.07565e-07\n",
            "[40000]\tvalid_0's multi_logloss: 9.1775e-08\n",
            "[41000]\tvalid_0's multi_logloss: 7.81071e-08\n",
            "[42000]\tvalid_0's multi_logloss: 6.61411e-08\n",
            "[43000]\tvalid_0's multi_logloss: 5.65751e-08\n",
            "[44000]\tvalid_0's multi_logloss: 5.49708e-08\n",
            "[45000]\tvalid_0's multi_logloss: 5.24565e-08\n",
            "[46000]\tvalid_0's multi_logloss: 4.69651e-08\n",
            "[47000]\tvalid_0's multi_logloss: 4.10685e-08\n",
            "[48000]\tvalid_0's multi_logloss: 4.10825e-08\n",
            "[49000]\tvalid_0's multi_logloss: 4.00535e-08\n",
            "[50000]\tvalid_0's multi_logloss: 3.95465e-08\n",
            "[51000]\tvalid_0's multi_logloss: 3.76576e-08\n",
            "[52000]\tvalid_0's multi_logloss: 3.65895e-08\n",
            "[53000]\tvalid_0's multi_logloss: 3.56275e-08\n",
            "[54000]\tvalid_0's multi_logloss: 3.49038e-08\n",
            "[55000]\tvalid_0's multi_logloss: 3.45994e-08\n",
            "[56000]\tvalid_0's multi_logloss: 3.40909e-08\n",
            "[57000]\tvalid_0's multi_logloss: 3.46373e-08\n",
            "[58000]\tvalid_0's multi_logloss: 3.46632e-08\n",
            "Early stopping, best iteration is:\n",
            "[56169]\tvalid_0's multi_logloss: 3.3994e-08\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.486129\n",
            "[2000]\tvalid_0's multi_logloss: 0.24486\n",
            "[3000]\tvalid_0's multi_logloss: 0.160402\n",
            "[4000]\tvalid_0's multi_logloss: 0.137444\n",
            "[5000]\tvalid_0's multi_logloss: 0.121878\n",
            "[6000]\tvalid_0's multi_logloss: 0.106695\n",
            "[7000]\tvalid_0's multi_logloss: 0.104839\n",
            "[8000]\tvalid_0's multi_logloss: 0.103501\n",
            "[9000]\tvalid_0's multi_logloss: 0.125747\n",
            "Early stopping, best iteration is:\n",
            "[7334]\tvalid_0's multi_logloss: 0.0995167\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.599518\n",
            "[2000]\tvalid_0's multi_logloss: 0.373682\n",
            "[3000]\tvalid_0's multi_logloss: 0.25404\n",
            "[4000]\tvalid_0's multi_logloss: 0.200804\n",
            "[5000]\tvalid_0's multi_logloss: 0.156802\n",
            "[6000]\tvalid_0's multi_logloss: 0.125093\n",
            "[7000]\tvalid_0's multi_logloss: 0.104842\n",
            "[8000]\tvalid_0's multi_logloss: 0.110113\n",
            "[9000]\tvalid_0's multi_logloss: 0.0981461\n",
            "[10000]\tvalid_0's multi_logloss: 0.0882426\n",
            "[11000]\tvalid_0's multi_logloss: 0.0795822\n",
            "[12000]\tvalid_0's multi_logloss: 0.065841\n",
            "[13000]\tvalid_0's multi_logloss: 0.0591751\n",
            "[14000]\tvalid_0's multi_logloss: 0.0499597\n",
            "[15000]\tvalid_0's multi_logloss: 0.0436533\n",
            "[16000]\tvalid_0's multi_logloss: 0.0394449\n",
            "[17000]\tvalid_0's multi_logloss: 0.0356855\n",
            "[18000]\tvalid_0's multi_logloss: 0.0332175\n",
            "[19000]\tvalid_0's multi_logloss: 0.030921\n",
            "[20000]\tvalid_0's multi_logloss: 0.0289476\n",
            "[21000]\tvalid_0's multi_logloss: 0.0275539\n",
            "[22000]\tvalid_0's multi_logloss: 0.028631\n",
            "Early stopping, best iteration is:\n",
            "[20846]\tvalid_0's multi_logloss: 0.0273873\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.572311\n",
            "[2000]\tvalid_0's multi_logloss: 0.311682\n",
            "[3000]\tvalid_0's multi_logloss: 0.167868\n",
            "[4000]\tvalid_0's multi_logloss: 0.0970134\n",
            "[5000]\tvalid_0's multi_logloss: 0.0754045\n",
            "[6000]\tvalid_0's multi_logloss: 0.0627142\n",
            "[7000]\tvalid_0's multi_logloss: 0.0456582\n",
            "[8000]\tvalid_0's multi_logloss: 0.0324198\n",
            "[9000]\tvalid_0's multi_logloss: 0.0237014\n",
            "[10000]\tvalid_0's multi_logloss: 0.0199437\n",
            "[11000]\tvalid_0's multi_logloss: 0.0176838\n",
            "[12000]\tvalid_0's multi_logloss: 0.0160392\n",
            "[13000]\tvalid_0's multi_logloss: 0.0152418\n",
            "[14000]\tvalid_0's multi_logloss: 0.0144069\n",
            "[15000]\tvalid_0's multi_logloss: 0.0140588\n",
            "[16000]\tvalid_0's multi_logloss: 0.0140362\n",
            "[17000]\tvalid_0's multi_logloss: 0.0133665\n",
            "[18000]\tvalid_0's multi_logloss: 0.0124284\n",
            "[19000]\tvalid_0's multi_logloss: 0.0123984\n",
            "[20000]\tvalid_0's multi_logloss: 0.0118563\n",
            "[21000]\tvalid_0's multi_logloss: 0.0115181\n",
            "[22000]\tvalid_0's multi_logloss: 0.0112348\n",
            "[23000]\tvalid_0's multi_logloss: 0.00956461\n",
            "[24000]\tvalid_0's multi_logloss: 0.00860579\n",
            "[25000]\tvalid_0's multi_logloss: 0.00860759\n",
            "[26000]\tvalid_0's multi_logloss: 0.00858452\n",
            "[27000]\tvalid_0's multi_logloss: 0.00826777\n",
            "[28000]\tvalid_0's multi_logloss: 0.00740983\n",
            "[29000]\tvalid_0's multi_logloss: 0.00620434\n",
            "[30000]\tvalid_0's multi_logloss: 0.00515948\n",
            "[31000]\tvalid_0's multi_logloss: 0.00373217\n",
            "[32000]\tvalid_0's multi_logloss: 0.00312471\n",
            "[33000]\tvalid_0's multi_logloss: 0.00259068\n",
            "[34000]\tvalid_0's multi_logloss: 0.00229354\n",
            "[35000]\tvalid_0's multi_logloss: 0.00210126\n",
            "[36000]\tvalid_0's multi_logloss: 0.00205586\n",
            "[37000]\tvalid_0's multi_logloss: 0.0019754\n",
            "[38000]\tvalid_0's multi_logloss: 0.00160193\n",
            "[39000]\tvalid_0's multi_logloss: 0.00147914\n",
            "[40000]\tvalid_0's multi_logloss: 0.00132906\n",
            "[41000]\tvalid_0's multi_logloss: 0.00171077\n",
            "Early stopping, best iteration is:\n",
            "[39691]\tvalid_0's multi_logloss: 0.0012602\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.521794\n",
            "[2000]\tvalid_0's multi_logloss: 0.286645\n",
            "[3000]\tvalid_0's multi_logloss: 0.164324\n",
            "[4000]\tvalid_0's multi_logloss: 0.106823\n",
            "[5000]\tvalid_0's multi_logloss: 0.0814056\n",
            "[6000]\tvalid_0's multi_logloss: 0.0706675\n",
            "[7000]\tvalid_0's multi_logloss: 0.0681301\n",
            "[8000]\tvalid_0's multi_logloss: 0.0577249\n",
            "[9000]\tvalid_0's multi_logloss: 0.0526717\n",
            "[10000]\tvalid_0's multi_logloss: 0.0480596\n",
            "[11000]\tvalid_0's multi_logloss: 0.0511506\n",
            "[12000]\tvalid_0's multi_logloss: 0.0538374\n",
            "Early stopping, best iteration is:\n",
            "[10255]\tvalid_0's multi_logloss: 0.0461696\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.500733\n",
            "[2000]\tvalid_0's multi_logloss: 0.295708\n",
            "[3000]\tvalid_0's multi_logloss: 0.234442\n",
            "[4000]\tvalid_0's multi_logloss: 0.198264\n",
            "[5000]\tvalid_0's multi_logloss: 0.173276\n",
            "[6000]\tvalid_0's multi_logloss: 0.173958\n",
            "[7000]\tvalid_0's multi_logloss: 0.17806\n",
            "Early stopping, best iteration is:\n",
            "[5619]\tvalid_0's multi_logloss: 0.169699\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.404732\n",
            "[2000]\tvalid_0's multi_logloss: 0.1688\n",
            "[3000]\tvalid_0's multi_logloss: 0.0726576\n",
            "[4000]\tvalid_0's multi_logloss: 0.0344654\n",
            "[5000]\tvalid_0's multi_logloss: 0.0190893\n",
            "[6000]\tvalid_0's multi_logloss: 0.0112847\n",
            "[7000]\tvalid_0's multi_logloss: 0.00676841\n",
            "[8000]\tvalid_0's multi_logloss: 0.00411998\n",
            "[9000]\tvalid_0's multi_logloss: 0.00278429\n",
            "[10000]\tvalid_0's multi_logloss: 0.00180518\n",
            "[11000]\tvalid_0's multi_logloss: 0.00123384\n",
            "[12000]\tvalid_0's multi_logloss: 0.00080774\n",
            "[13000]\tvalid_0's multi_logloss: 0.000515318\n",
            "[14000]\tvalid_0's multi_logloss: 0.000313958\n",
            "[15000]\tvalid_0's multi_logloss: 0.00021787\n",
            "[16000]\tvalid_0's multi_logloss: 0.000158006\n",
            "[17000]\tvalid_0's multi_logloss: 0.000113857\n",
            "[18000]\tvalid_0's multi_logloss: 7.87914e-05\n",
            "[19000]\tvalid_0's multi_logloss: 5.60587e-05\n",
            "[20000]\tvalid_0's multi_logloss: 3.65011e-05\n",
            "[21000]\tvalid_0's multi_logloss: 2.5645e-05\n",
            "[22000]\tvalid_0's multi_logloss: 1.7555e-05\n",
            "[23000]\tvalid_0's multi_logloss: 1.18248e-05\n",
            "[24000]\tvalid_0's multi_logloss: 9.24878e-06\n",
            "[25000]\tvalid_0's multi_logloss: 6.72442e-06\n",
            "[26000]\tvalid_0's multi_logloss: 4.97409e-06\n",
            "[27000]\tvalid_0's multi_logloss: 3.39628e-06\n",
            "[28000]\tvalid_0's multi_logloss: 2.26894e-06\n",
            "[29000]\tvalid_0's multi_logloss: 1.6551e-06\n",
            "[30000]\tvalid_0's multi_logloss: 1.29011e-06\n",
            "[31000]\tvalid_0's multi_logloss: 1.03709e-06\n",
            "[32000]\tvalid_0's multi_logloss: 8.12501e-07\n",
            "[33000]\tvalid_0's multi_logloss: 6.60562e-07\n",
            "[34000]\tvalid_0's multi_logloss: 5.12204e-07\n",
            "[35000]\tvalid_0's multi_logloss: 3.8725e-07\n",
            "[36000]\tvalid_0's multi_logloss: 3.51402e-07\n",
            "[37000]\tvalid_0's multi_logloss: 3.37145e-07\n",
            "[38000]\tvalid_0's multi_logloss: 2.87248e-07\n",
            "[39000]\tvalid_0's multi_logloss: 2.47193e-07\n",
            "[40000]\tvalid_0's multi_logloss: 2.01827e-07\n",
            "[41000]\tvalid_0's multi_logloss: 1.74426e-07\n",
            "[42000]\tvalid_0's multi_logloss: 1.56506e-07\n",
            "[43000]\tvalid_0's multi_logloss: 1.36632e-07\n",
            "[44000]\tvalid_0's multi_logloss: 1.24816e-07\n",
            "[45000]\tvalid_0's multi_logloss: 1.17202e-07\n",
            "[46000]\tvalid_0's multi_logloss: 1.06051e-07\n",
            "[47000]\tvalid_0's multi_logloss: 9.58229e-08\n",
            "[48000]\tvalid_0's multi_logloss: 8.67111e-08\n",
            "[49000]\tvalid_0's multi_logloss: 7.96638e-08\n",
            "[50000]\tvalid_0's multi_logloss: 7.43762e-08\n",
            "[51000]\tvalid_0's multi_logloss: 6.69724e-08\n",
            "[52000]\tvalid_0's multi_logloss: 6.29216e-08\n",
            "[53000]\tvalid_0's multi_logloss: 5.94905e-08\n",
            "[54000]\tvalid_0's multi_logloss: 5.56306e-08\n",
            "[55000]\tvalid_0's multi_logloss: 5.09316e-08\n",
            "[56000]\tvalid_0's multi_logloss: 4.86056e-08\n",
            "[57000]\tvalid_0's multi_logloss: 4.64187e-08\n",
            "[58000]\tvalid_0's multi_logloss: 4.52215e-08\n",
            "[59000]\tvalid_0's multi_logloss: 4.32168e-08\n",
            "[60000]\tvalid_0's multi_logloss: 4.00821e-08\n",
            "[61000]\tvalid_0's multi_logloss: 3.81979e-08\n",
            "[62000]\tvalid_0's multi_logloss: 3.61448e-08\n",
            "[63000]\tvalid_0's multi_logloss: 3.40081e-08\n",
            "[64000]\tvalid_0's multi_logloss: 3.20945e-08\n",
            "[65000]\tvalid_0's multi_logloss: 2.99939e-08\n",
            "[66000]\tvalid_0's multi_logloss: 2.84327e-08\n",
            "[67000]\tvalid_0's multi_logloss: 2.72524e-08\n",
            "[68000]\tvalid_0's multi_logloss: 2.61864e-08\n",
            "[69000]\tvalid_0's multi_logloss: 2.51169e-08\n",
            "[70000]\tvalid_0's multi_logloss: 2.41347e-08\n",
            "[71000]\tvalid_0's multi_logloss: 2.32098e-08\n",
            "[72000]\tvalid_0's multi_logloss: 2.2017e-08\n",
            "[73000]\tvalid_0's multi_logloss: 2.09395e-08\n",
            "[74000]\tvalid_0's multi_logloss: 2.02085e-08\n",
            "[75000]\tvalid_0's multi_logloss: 2.00684e-08\n",
            "[76000]\tvalid_0's multi_logloss: 1.86921e-08\n",
            "[77000]\tvalid_0's multi_logloss: 1.84734e-08\n",
            "[78000]\tvalid_0's multi_logloss: 1.85106e-08\n",
            "[79000]\tvalid_0's multi_logloss: 1.87503e-08\n",
            "Early stopping, best iteration is:\n",
            "[77231]\tvalid_0's multi_logloss: 1.84455e-08\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.485145\n",
            "[2000]\tvalid_0's multi_logloss: 0.199074\n",
            "[3000]\tvalid_0's multi_logloss: 0.0947234\n",
            "[4000]\tvalid_0's multi_logloss: 0.0546435\n",
            "[5000]\tvalid_0's multi_logloss: 0.0337086\n",
            "[6000]\tvalid_0's multi_logloss: 0.0237763\n",
            "[7000]\tvalid_0's multi_logloss: 0.0157794\n",
            "[8000]\tvalid_0's multi_logloss: 0.0101695\n",
            "[9000]\tvalid_0's multi_logloss: 0.00657843\n",
            "[10000]\tvalid_0's multi_logloss: 0.0043533\n",
            "[11000]\tvalid_0's multi_logloss: 0.00282475\n",
            "[12000]\tvalid_0's multi_logloss: 0.00203017\n",
            "[13000]\tvalid_0's multi_logloss: 0.00133513\n",
            "[14000]\tvalid_0's multi_logloss: 0.000925352\n",
            "[15000]\tvalid_0's multi_logloss: 0.000663974\n",
            "[16000]\tvalid_0's multi_logloss: 0.000489259\n",
            "[17000]\tvalid_0's multi_logloss: 0.000348448\n",
            "[18000]\tvalid_0's multi_logloss: 0.000230333\n",
            "[19000]\tvalid_0's multi_logloss: 0.000158099\n",
            "[20000]\tvalid_0's multi_logloss: 0.00010302\n",
            "[21000]\tvalid_0's multi_logloss: 6.86029e-05\n",
            "[22000]\tvalid_0's multi_logloss: 4.62186e-05\n",
            "[23000]\tvalid_0's multi_logloss: 3.02825e-05\n",
            "[24000]\tvalid_0's multi_logloss: 2.08339e-05\n",
            "[25000]\tvalid_0's multi_logloss: 1.60976e-05\n",
            "[26000]\tvalid_0's multi_logloss: 1.12582e-05\n",
            "[27000]\tvalid_0's multi_logloss: 8.22091e-06\n",
            "[28000]\tvalid_0's multi_logloss: 6.19775e-06\n",
            "[29000]\tvalid_0's multi_logloss: 4.58873e-06\n",
            "[30000]\tvalid_0's multi_logloss: 3.45935e-06\n",
            "[31000]\tvalid_0's multi_logloss: 2.99066e-06\n",
            "[32000]\tvalid_0's multi_logloss: 2.63493e-06\n",
            "[33000]\tvalid_0's multi_logloss: 1.95988e-06\n",
            "[34000]\tvalid_0's multi_logloss: 1.48663e-06\n",
            "[35000]\tvalid_0's multi_logloss: 9.85585e-07\n",
            "[36000]\tvalid_0's multi_logloss: 6.91267e-07\n",
            "[37000]\tvalid_0's multi_logloss: 5.69031e-07\n",
            "[38000]\tvalid_0's multi_logloss: 4.31581e-07\n",
            "[39000]\tvalid_0's multi_logloss: 3.04905e-07\n",
            "[40000]\tvalid_0's multi_logloss: 2.62879e-07\n",
            "[41000]\tvalid_0's multi_logloss: 1.9845e-07\n",
            "[42000]\tvalid_0's multi_logloss: 1.64526e-07\n",
            "[43000]\tvalid_0's multi_logloss: 1.48054e-07\n",
            "[44000]\tvalid_0's multi_logloss: 1.27145e-07\n",
            "[45000]\tvalid_0's multi_logloss: 1.29227e-07\n",
            "[46000]\tvalid_0's multi_logloss: 1.20496e-07\n",
            "[47000]\tvalid_0's multi_logloss: 1.04282e-07\n",
            "[48000]\tvalid_0's multi_logloss: 9.5063e-08\n",
            "[49000]\tvalid_0's multi_logloss: 9.22195e-08\n",
            "[50000]\tvalid_0's multi_logloss: 8.97919e-08\n",
            "[51000]\tvalid_0's multi_logloss: 8.8471e-08\n",
            "[52000]\tvalid_0's multi_logloss: 9.08786e-08\n",
            "Early stopping, best iteration is:\n",
            "[50911]\tvalid_0's multi_logloss: 8.80495e-08\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.732622\n",
            "[2000]\tvalid_0's multi_logloss: 0.538287\n",
            "[3000]\tvalid_0's multi_logloss: 0.409277\n",
            "[4000]\tvalid_0's multi_logloss: 0.34515\n",
            "[5000]\tvalid_0's multi_logloss: 0.3224\n",
            "[6000]\tvalid_0's multi_logloss: 0.297894\n",
            "[7000]\tvalid_0's multi_logloss: 0.294859\n",
            "[8000]\tvalid_0's multi_logloss: 0.307878\n",
            "Early stopping, best iteration is:\n",
            "[6825]\tvalid_0's multi_logloss: 0.289881\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.55489\n",
            "[2000]\tvalid_0's multi_logloss: 0.321414\n",
            "[3000]\tvalid_0's multi_logloss: 0.173972\n",
            "[4000]\tvalid_0's multi_logloss: 0.0930494\n",
            "[5000]\tvalid_0's multi_logloss: 0.0530347\n",
            "[6000]\tvalid_0's multi_logloss: 0.0326097\n",
            "[7000]\tvalid_0's multi_logloss: 0.0185918\n",
            "[8000]\tvalid_0's multi_logloss: 0.0126197\n",
            "[9000]\tvalid_0's multi_logloss: 0.00860248\n",
            "[10000]\tvalid_0's multi_logloss: 0.00614711\n",
            "[11000]\tvalid_0's multi_logloss: 0.00460099\n",
            "[12000]\tvalid_0's multi_logloss: 0.00339153\n",
            "[13000]\tvalid_0's multi_logloss: 0.00253672\n",
            "[14000]\tvalid_0's multi_logloss: 0.00225748\n",
            "[15000]\tvalid_0's multi_logloss: 0.00191243\n",
            "[16000]\tvalid_0's multi_logloss: 0.00164721\n",
            "[17000]\tvalid_0's multi_logloss: 0.00152598\n",
            "[18000]\tvalid_0's multi_logloss: 0.00114048\n",
            "[19000]\tvalid_0's multi_logloss: 0.000931492\n",
            "[20000]\tvalid_0's multi_logloss: 0.000898999\n",
            "[21000]\tvalid_0's multi_logloss: 0.000799341\n",
            "[22000]\tvalid_0's multi_logloss: 0.000689485\n",
            "[23000]\tvalid_0's multi_logloss: 0.00068983\n",
            "[24000]\tvalid_0's multi_logloss: 0.000689081\n",
            "Early stopping, best iteration is:\n",
            "[22226]\tvalid_0's multi_logloss: 0.000670173\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.610519\n",
            "[2000]\tvalid_0's multi_logloss: 0.356465\n",
            "[3000]\tvalid_0's multi_logloss: 0.218771\n",
            "[4000]\tvalid_0's multi_logloss: 0.143309\n",
            "[5000]\tvalid_0's multi_logloss: 0.0949194\n",
            "[6000]\tvalid_0's multi_logloss: 0.0676229\n",
            "[7000]\tvalid_0's multi_logloss: 0.0517462\n",
            "[8000]\tvalid_0's multi_logloss: 0.049065\n",
            "[9000]\tvalid_0's multi_logloss: 0.0449445\n",
            "[10000]\tvalid_0's multi_logloss: 0.0388036\n",
            "[11000]\tvalid_0's multi_logloss: 0.0303007\n",
            "[12000]\tvalid_0's multi_logloss: 0.0288063\n",
            "[13000]\tvalid_0's multi_logloss: 0.0266534\n",
            "[14000]\tvalid_0's multi_logloss: 0.0236762\n",
            "[15000]\tvalid_0's multi_logloss: 0.022165\n",
            "[16000]\tvalid_0's multi_logloss: 0.0211543\n",
            "[17000]\tvalid_0's multi_logloss: 0.0214584\n",
            "[18000]\tvalid_0's multi_logloss: 0.0218353\n",
            "Early stopping, best iteration is:\n",
            "[16285]\tvalid_0's multi_logloss: 0.0209109\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.540234\n",
            "[2000]\tvalid_0's multi_logloss: 0.297248\n",
            "[3000]\tvalid_0's multi_logloss: 0.22147\n",
            "[4000]\tvalid_0's multi_logloss: 0.20402\n",
            "[5000]\tvalid_0's multi_logloss: 0.192362\n",
            "[6000]\tvalid_0's multi_logloss: 0.192224\n",
            "[7000]\tvalid_0's multi_logloss: 0.191735\n",
            "Early stopping, best iteration is:\n",
            "[5634]\tvalid_0's multi_logloss: 0.188858\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.4763\n",
            "[2000]\tvalid_0's multi_logloss: 0.231752\n",
            "[3000]\tvalid_0's multi_logloss: 0.118843\n",
            "[4000]\tvalid_0's multi_logloss: 0.0750091\n",
            "[5000]\tvalid_0's multi_logloss: 0.0434548\n",
            "[6000]\tvalid_0's multi_logloss: 0.0282277\n",
            "[7000]\tvalid_0's multi_logloss: 0.0175171\n",
            "[8000]\tvalid_0's multi_logloss: 0.0107746\n",
            "[9000]\tvalid_0's multi_logloss: 0.00899961\n",
            "[10000]\tvalid_0's multi_logloss: 0.00691726\n",
            "[11000]\tvalid_0's multi_logloss: 0.00498322\n",
            "[12000]\tvalid_0's multi_logloss: 0.0038372\n",
            "[13000]\tvalid_0's multi_logloss: 0.00302004\n",
            "[14000]\tvalid_0's multi_logloss: 0.00234128\n",
            "[15000]\tvalid_0's multi_logloss: 0.00167477\n",
            "[16000]\tvalid_0's multi_logloss: 0.00136324\n",
            "[17000]\tvalid_0's multi_logloss: 0.00106178\n",
            "[18000]\tvalid_0's multi_logloss: 0.000834543\n",
            "[19000]\tvalid_0's multi_logloss: 0.000632245\n",
            "[20000]\tvalid_0's multi_logloss: 0.000509557\n",
            "[21000]\tvalid_0's multi_logloss: 0.000359161\n",
            "[22000]\tvalid_0's multi_logloss: 0.000283729\n",
            "[23000]\tvalid_0's multi_logloss: 0.000238438\n",
            "[24000]\tvalid_0's multi_logloss: 0.000194076\n",
            "[25000]\tvalid_0's multi_logloss: 0.000136819\n",
            "[26000]\tvalid_0's multi_logloss: 9.58928e-05\n",
            "[27000]\tvalid_0's multi_logloss: 6.78807e-05\n",
            "[28000]\tvalid_0's multi_logloss: 5.19894e-05\n",
            "[29000]\tvalid_0's multi_logloss: 4.70318e-05\n",
            "[30000]\tvalid_0's multi_logloss: 3.94016e-05\n",
            "[31000]\tvalid_0's multi_logloss: 2.97497e-05\n",
            "[32000]\tvalid_0's multi_logloss: 2.18777e-05\n",
            "[33000]\tvalid_0's multi_logloss: 1.62626e-05\n",
            "[34000]\tvalid_0's multi_logloss: 1.20685e-05\n",
            "[35000]\tvalid_0's multi_logloss: 8.96396e-06\n",
            "[36000]\tvalid_0's multi_logloss: 7.55774e-06\n",
            "[37000]\tvalid_0's multi_logloss: 6.20422e-06\n",
            "[38000]\tvalid_0's multi_logloss: 5.10288e-06\n",
            "[39000]\tvalid_0's multi_logloss: 4.35851e-06\n",
            "[40000]\tvalid_0's multi_logloss: 3.71245e-06\n",
            "[41000]\tvalid_0's multi_logloss: 3.46564e-06\n",
            "[42000]\tvalid_0's multi_logloss: 2.65649e-06\n",
            "[43000]\tvalid_0's multi_logloss: 2.04689e-06\n",
            "[44000]\tvalid_0's multi_logloss: 1.89196e-06\n",
            "[45000]\tvalid_0's multi_logloss: 1.91094e-06\n",
            "[46000]\tvalid_0's multi_logloss: 2.04358e-06\n",
            "Early stopping, best iteration is:\n",
            "[44395]\tvalid_0's multi_logloss: 1.8745e-06\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.513866\n",
            "[2000]\tvalid_0's multi_logloss: 0.239228\n",
            "[3000]\tvalid_0's multi_logloss: 0.125473\n",
            "[4000]\tvalid_0's multi_logloss: 0.0797703\n",
            "[5000]\tvalid_0's multi_logloss: 0.0497248\n",
            "[6000]\tvalid_0's multi_logloss: 0.0327212\n",
            "[7000]\tvalid_0's multi_logloss: 0.0220501\n",
            "[8000]\tvalid_0's multi_logloss: 0.0146112\n",
            "[9000]\tvalid_0's multi_logloss: 0.0095282\n",
            "[10000]\tvalid_0's multi_logloss: 0.00648219\n",
            "[11000]\tvalid_0's multi_logloss: 0.00485347\n",
            "[12000]\tvalid_0's multi_logloss: 0.00317239\n",
            "[13000]\tvalid_0's multi_logloss: 0.0020668\n",
            "[14000]\tvalid_0's multi_logloss: 0.00142085\n",
            "[15000]\tvalid_0's multi_logloss: 0.000897099\n",
            "[16000]\tvalid_0's multi_logloss: 0.000594054\n",
            "[17000]\tvalid_0's multi_logloss: 0.000387568\n",
            "[18000]\tvalid_0's multi_logloss: 0.000267332\n",
            "[19000]\tvalid_0's multi_logloss: 0.000196961\n",
            "[20000]\tvalid_0's multi_logloss: 0.000151123\n",
            "[21000]\tvalid_0's multi_logloss: 0.000121594\n",
            "[22000]\tvalid_0's multi_logloss: 0.000102196\n",
            "[23000]\tvalid_0's multi_logloss: 8.4982e-05\n",
            "[24000]\tvalid_0's multi_logloss: 6.51977e-05\n",
            "[25000]\tvalid_0's multi_logloss: 5.24959e-05\n",
            "[26000]\tvalid_0's multi_logloss: 4.08652e-05\n",
            "[27000]\tvalid_0's multi_logloss: 3.31658e-05\n",
            "[28000]\tvalid_0's multi_logloss: 2.73176e-05\n",
            "[29000]\tvalid_0's multi_logloss: 2.14943e-05\n",
            "[30000]\tvalid_0's multi_logloss: 1.69556e-05\n",
            "[31000]\tvalid_0's multi_logloss: 1.17856e-05\n",
            "[32000]\tvalid_0's multi_logloss: 7.65077e-06\n",
            "[33000]\tvalid_0's multi_logloss: 6.10889e-06\n",
            "[34000]\tvalid_0's multi_logloss: 4.78236e-06\n",
            "[35000]\tvalid_0's multi_logloss: 3.82323e-06\n",
            "[36000]\tvalid_0's multi_logloss: 3.23376e-06\n",
            "[37000]\tvalid_0's multi_logloss: 2.69922e-06\n",
            "[38000]\tvalid_0's multi_logloss: 2.30587e-06\n",
            "[39000]\tvalid_0's multi_logloss: 1.94055e-06\n",
            "[40000]\tvalid_0's multi_logloss: 1.63691e-06\n",
            "[41000]\tvalid_0's multi_logloss: 1.35628e-06\n",
            "[42000]\tvalid_0's multi_logloss: 1.28016e-06\n",
            "[43000]\tvalid_0's multi_logloss: 1.22125e-06\n",
            "[44000]\tvalid_0's multi_logloss: 1.16254e-06\n",
            "[45000]\tvalid_0's multi_logloss: 1.08535e-06\n",
            "[46000]\tvalid_0's multi_logloss: 1.04275e-06\n",
            "[47000]\tvalid_0's multi_logloss: 1.03856e-06\n",
            "[48000]\tvalid_0's multi_logloss: 9.84728e-07\n",
            "[49000]\tvalid_0's multi_logloss: 9.53654e-07\n",
            "[50000]\tvalid_0's multi_logloss: 9.71079e-07\n",
            "Early stopping, best iteration is:\n",
            "[48797]\tvalid_0's multi_logloss: 9.52468e-07\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.355945\n",
            "[2000]\tvalid_0's multi_logloss: 0.142493\n",
            "[3000]\tvalid_0's multi_logloss: 0.0639055\n",
            "[4000]\tvalid_0's multi_logloss: 0.029939\n",
            "[5000]\tvalid_0's multi_logloss: 0.01611\n",
            "[6000]\tvalid_0's multi_logloss: 0.00884284\n",
            "[7000]\tvalid_0's multi_logloss: 0.00534116\n",
            "[8000]\tvalid_0's multi_logloss: 0.0038359\n",
            "[9000]\tvalid_0's multi_logloss: 0.00258766\n",
            "[10000]\tvalid_0's multi_logloss: 0.00178244\n",
            "[11000]\tvalid_0's multi_logloss: 0.00127031\n",
            "[12000]\tvalid_0's multi_logloss: 0.000977491\n",
            "[13000]\tvalid_0's multi_logloss: 0.000750859\n",
            "[14000]\tvalid_0's multi_logloss: 0.000612758\n",
            "[15000]\tvalid_0's multi_logloss: 0.000504972\n",
            "[16000]\tvalid_0's multi_logloss: 0.000391711\n",
            "[17000]\tvalid_0's multi_logloss: 0.00033843\n",
            "[18000]\tvalid_0's multi_logloss: 0.000257438\n",
            "[19000]\tvalid_0's multi_logloss: 0.000205388\n",
            "[20000]\tvalid_0's multi_logloss: 0.000165142\n",
            "[21000]\tvalid_0's multi_logloss: 0.000112215\n",
            "[22000]\tvalid_0's multi_logloss: 6.99024e-05\n",
            "[23000]\tvalid_0's multi_logloss: 5.15065e-05\n",
            "[24000]\tvalid_0's multi_logloss: 3.69663e-05\n",
            "[25000]\tvalid_0's multi_logloss: 2.70335e-05\n",
            "[26000]\tvalid_0's multi_logloss: 2.07033e-05\n",
            "[27000]\tvalid_0's multi_logloss: 1.55808e-05\n",
            "[28000]\tvalid_0's multi_logloss: 1.24353e-05\n",
            "[29000]\tvalid_0's multi_logloss: 9.96038e-06\n",
            "[30000]\tvalid_0's multi_logloss: 8.54882e-06\n",
            "[31000]\tvalid_0's multi_logloss: 7.63271e-06\n",
            "[32000]\tvalid_0's multi_logloss: 6.7015e-06\n",
            "[33000]\tvalid_0's multi_logloss: 5.48086e-06\n",
            "[34000]\tvalid_0's multi_logloss: 5.07649e-06\n",
            "[35000]\tvalid_0's multi_logloss: 4.52629e-06\n",
            "[36000]\tvalid_0's multi_logloss: 4.12199e-06\n",
            "[37000]\tvalid_0's multi_logloss: 3.8257e-06\n",
            "[38000]\tvalid_0's multi_logloss: 4.22446e-06\n",
            "[39000]\tvalid_0's multi_logloss: 4.43873e-06\n",
            "Early stopping, best iteration is:\n",
            "[37259]\tvalid_0's multi_logloss: 3.81621e-06\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.476955\n",
            "[2000]\tvalid_0's multi_logloss: 0.231448\n",
            "[3000]\tvalid_0's multi_logloss: 0.126484\n",
            "[4000]\tvalid_0's multi_logloss: 0.0653966\n",
            "[5000]\tvalid_0's multi_logloss: 0.0340624\n",
            "[6000]\tvalid_0's multi_logloss: 0.0195328\n",
            "[7000]\tvalid_0's multi_logloss: 0.0111805\n",
            "[8000]\tvalid_0's multi_logloss: 0.00711201\n",
            "[9000]\tvalid_0's multi_logloss: 0.00414967\n",
            "[10000]\tvalid_0's multi_logloss: 0.00266825\n",
            "[11000]\tvalid_0's multi_logloss: 0.00242938\n",
            "[12000]\tvalid_0's multi_logloss: 0.00203996\n",
            "[13000]\tvalid_0's multi_logloss: 0.00161973\n",
            "[14000]\tvalid_0's multi_logloss: 0.000988973\n",
            "[15000]\tvalid_0's multi_logloss: 0.000809586\n",
            "[16000]\tvalid_0's multi_logloss: 0.000668329\n",
            "[17000]\tvalid_0's multi_logloss: 0.000502662\n",
            "[18000]\tvalid_0's multi_logloss: 0.000401385\n",
            "[19000]\tvalid_0's multi_logloss: 0.000333324\n",
            "[20000]\tvalid_0's multi_logloss: 0.00027516\n",
            "[21000]\tvalid_0's multi_logloss: 0.000231508\n",
            "[22000]\tvalid_0's multi_logloss: 0.000171209\n",
            "[23000]\tvalid_0's multi_logloss: 0.000121981\n",
            "[24000]\tvalid_0's multi_logloss: 8.73489e-05\n",
            "[25000]\tvalid_0's multi_logloss: 4.74925e-05\n",
            "[26000]\tvalid_0's multi_logloss: 3.14557e-05\n",
            "[27000]\tvalid_0's multi_logloss: 2.18434e-05\n",
            "[28000]\tvalid_0's multi_logloss: 1.58097e-05\n",
            "[29000]\tvalid_0's multi_logloss: 1.30058e-05\n",
            "[30000]\tvalid_0's multi_logloss: 1.02689e-05\n",
            "[31000]\tvalid_0's multi_logloss: 9.94762e-06\n",
            "[32000]\tvalid_0's multi_logloss: 8.58962e-06\n",
            "[33000]\tvalid_0's multi_logloss: 7.58985e-06\n",
            "[34000]\tvalid_0's multi_logloss: 6.06446e-06\n",
            "[35000]\tvalid_0's multi_logloss: 5.25184e-06\n",
            "[36000]\tvalid_0's multi_logloss: 4.59115e-06\n",
            "[37000]\tvalid_0's multi_logloss: 4.76771e-06\n",
            "Early stopping, best iteration is:\n",
            "[35740]\tvalid_0's multi_logloss: 4.49788e-06\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.369612\n",
            "[2000]\tvalid_0's multi_logloss: 0.164617\n",
            "[3000]\tvalid_0's multi_logloss: 0.0804866\n",
            "[4000]\tvalid_0's multi_logloss: 0.0472126\n",
            "[5000]\tvalid_0's multi_logloss: 0.0329734\n",
            "[6000]\tvalid_0's multi_logloss: 0.0219142\n",
            "[7000]\tvalid_0's multi_logloss: 0.0151685\n",
            "[8000]\tvalid_0's multi_logloss: 0.0130998\n",
            "[9000]\tvalid_0's multi_logloss: 0.0130381\n",
            "[10000]\tvalid_0's multi_logloss: 0.0112938\n",
            "[11000]\tvalid_0's multi_logloss: 0.00940863\n",
            "[12000]\tvalid_0's multi_logloss: 0.00738922\n",
            "[13000]\tvalid_0's multi_logloss: 0.00604313\n",
            "[14000]\tvalid_0's multi_logloss: 0.00504024\n",
            "[15000]\tvalid_0's multi_logloss: 0.00407434\n",
            "[16000]\tvalid_0's multi_logloss: 0.00349227\n",
            "[17000]\tvalid_0's multi_logloss: 0.00328517\n",
            "[18000]\tvalid_0's multi_logloss: 0.00287525\n",
            "[19000]\tvalid_0's multi_logloss: 0.00243473\n",
            "[20000]\tvalid_0's multi_logloss: 0.0021619\n",
            "[21000]\tvalid_0's multi_logloss: 0.0019223\n",
            "[22000]\tvalid_0's multi_logloss: 0.00169915\n",
            "[23000]\tvalid_0's multi_logloss: 0.00139835\n",
            "[24000]\tvalid_0's multi_logloss: 0.0011793\n",
            "[25000]\tvalid_0's multi_logloss: 0.00102083\n",
            "[26000]\tvalid_0's multi_logloss: 0.00101448\n",
            "[27000]\tvalid_0's multi_logloss: 0.000992028\n",
            "Early stopping, best iteration is:\n",
            "[25150]\tvalid_0's multi_logloss: 0.0009672\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.373631\n",
            "[2000]\tvalid_0's multi_logloss: 0.160049\n",
            "[3000]\tvalid_0's multi_logloss: 0.0727843\n",
            "[4000]\tvalid_0's multi_logloss: 0.0358257\n",
            "[5000]\tvalid_0's multi_logloss: 0.022507\n",
            "[6000]\tvalid_0's multi_logloss: 0.0140572\n",
            "[7000]\tvalid_0's multi_logloss: 0.00949719\n",
            "[8000]\tvalid_0's multi_logloss: 0.00753195\n",
            "[9000]\tvalid_0's multi_logloss: 0.00563385\n",
            "[10000]\tvalid_0's multi_logloss: 0.00450559\n",
            "[11000]\tvalid_0's multi_logloss: 0.00341823\n",
            "[12000]\tvalid_0's multi_logloss: 0.00309822\n",
            "[13000]\tvalid_0's multi_logloss: 0.0027961\n",
            "[14000]\tvalid_0's multi_logloss: 0.00283037\n",
            "[15000]\tvalid_0's multi_logloss: 0.00257492\n",
            "[16000]\tvalid_0's multi_logloss: 0.00185971\n",
            "[17000]\tvalid_0's multi_logloss: 0.00157239\n",
            "[18000]\tvalid_0's multi_logloss: 0.00126505\n",
            "[19000]\tvalid_0's multi_logloss: 0.000969733\n",
            "[20000]\tvalid_0's multi_logloss: 0.000813851\n",
            "[21000]\tvalid_0's multi_logloss: 0.000699166\n",
            "[22000]\tvalid_0's multi_logloss: 0.000659815\n",
            "[23000]\tvalid_0's multi_logloss: 0.00056994\n",
            "[24000]\tvalid_0's multi_logloss: 0.000396293\n",
            "[25000]\tvalid_0's multi_logloss: 0.000296641\n",
            "[26000]\tvalid_0's multi_logloss: 0.000208684\n",
            "[27000]\tvalid_0's multi_logloss: 0.000170364\n",
            "[28000]\tvalid_0's multi_logloss: 0.000116005\n",
            "[29000]\tvalid_0's multi_logloss: 8.06622e-05\n",
            "[30000]\tvalid_0's multi_logloss: 6.84217e-05\n",
            "[31000]\tvalid_0's multi_logloss: 5.81675e-05\n",
            "[32000]\tvalid_0's multi_logloss: 4.98258e-05\n",
            "[33000]\tvalid_0's multi_logloss: 4.08938e-05\n",
            "[34000]\tvalid_0's multi_logloss: 3.20597e-05\n",
            "[35000]\tvalid_0's multi_logloss: 2.5573e-05\n",
            "[36000]\tvalid_0's multi_logloss: 2.1424e-05\n",
            "[37000]\tvalid_0's multi_logloss: 1.75135e-05\n",
            "[38000]\tvalid_0's multi_logloss: 1.37442e-05\n",
            "[39000]\tvalid_0's multi_logloss: 1.02813e-05\n",
            "[40000]\tvalid_0's multi_logloss: 7.0298e-06\n",
            "[41000]\tvalid_0's multi_logloss: 5.15243e-06\n",
            "[42000]\tvalid_0's multi_logloss: 3.57261e-06\n",
            "[43000]\tvalid_0's multi_logloss: 3.15784e-06\n",
            "[44000]\tvalid_0's multi_logloss: 2.89523e-06\n",
            "[45000]\tvalid_0's multi_logloss: 2.4572e-06\n",
            "[46000]\tvalid_0's multi_logloss: 2.00925e-06\n",
            "[47000]\tvalid_0's multi_logloss: 1.90208e-06\n",
            "[48000]\tvalid_0's multi_logloss: 1.78279e-06\n",
            "[49000]\tvalid_0's multi_logloss: 1.68159e-06\n",
            "[50000]\tvalid_0's multi_logloss: 1.55434e-06\n",
            "[51000]\tvalid_0's multi_logloss: 1.40706e-06\n",
            "[52000]\tvalid_0's multi_logloss: 1.30136e-06\n",
            "[53000]\tvalid_0's multi_logloss: 1.26414e-06\n",
            "[54000]\tvalid_0's multi_logloss: 1.30334e-06\n",
            "Early stopping, best iteration is:\n",
            "[52648]\tvalid_0's multi_logloss: 1.26196e-06\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.353935\n",
            "[2000]\tvalid_0's multi_logloss: 0.148892\n",
            "[3000]\tvalid_0's multi_logloss: 0.0762101\n",
            "[4000]\tvalid_0's multi_logloss: 0.0473037\n",
            "[5000]\tvalid_0's multi_logloss: 0.0374171\n",
            "[6000]\tvalid_0's multi_logloss: 0.0310834\n",
            "[7000]\tvalid_0's multi_logloss: 0.0249645\n",
            "[8000]\tvalid_0's multi_logloss: 0.019579\n",
            "[9000]\tvalid_0's multi_logloss: 0.016722\n",
            "[10000]\tvalid_0's multi_logloss: 0.0130418\n",
            "[11000]\tvalid_0's multi_logloss: 0.0120331\n",
            "[12000]\tvalid_0's multi_logloss: 0.0111261\n",
            "[13000]\tvalid_0's multi_logloss: 0.00967809\n",
            "[14000]\tvalid_0's multi_logloss: 0.00928392\n",
            "[15000]\tvalid_0's multi_logloss: 0.00789083\n",
            "[16000]\tvalid_0's multi_logloss: 0.00759147\n",
            "[17000]\tvalid_0's multi_logloss: 0.00709331\n",
            "[18000]\tvalid_0's multi_logloss: 0.00688039\n",
            "[19000]\tvalid_0's multi_logloss: 0.00636167\n",
            "[20000]\tvalid_0's multi_logloss: 0.00604889\n",
            "[21000]\tvalid_0's multi_logloss: 0.00492345\n",
            "[22000]\tvalid_0's multi_logloss: 0.00447808\n",
            "[23000]\tvalid_0's multi_logloss: 0.0041262\n",
            "[24000]\tvalid_0's multi_logloss: 0.00358704\n",
            "[25000]\tvalid_0's multi_logloss: 0.00335359\n",
            "[26000]\tvalid_0's multi_logloss: 0.00329581\n",
            "[27000]\tvalid_0's multi_logloss: 0.00327852\n",
            "[28000]\tvalid_0's multi_logloss: 0.00312668\n",
            "[29000]\tvalid_0's multi_logloss: 0.00287385\n",
            "[30000]\tvalid_0's multi_logloss: 0.00275695\n",
            "[31000]\tvalid_0's multi_logloss: 0.00257144\n",
            "[32000]\tvalid_0's multi_logloss: 0.00228443\n",
            "[33000]\tvalid_0's multi_logloss: 0.00199238\n",
            "[34000]\tvalid_0's multi_logloss: 0.00194803\n",
            "[35000]\tvalid_0's multi_logloss: 0.00179836\n",
            "[36000]\tvalid_0's multi_logloss: 0.0015046\n",
            "[37000]\tvalid_0's multi_logloss: 0.00113753\n",
            "[38000]\tvalid_0's multi_logloss: 0.000949972\n",
            "[39000]\tvalid_0's multi_logloss: 0.000893391\n",
            "[40000]\tvalid_0's multi_logloss: 0.000873007\n",
            "[41000]\tvalid_0's multi_logloss: 0.000805579\n",
            "[42000]\tvalid_0's multi_logloss: 0.000665994\n",
            "[43000]\tvalid_0's multi_logloss: 0.000551928\n",
            "[44000]\tvalid_0's multi_logloss: 0.000423194\n",
            "[45000]\tvalid_0's multi_logloss: 0.000355116\n",
            "[46000]\tvalid_0's multi_logloss: 0.000314251\n",
            "[47000]\tvalid_0's multi_logloss: 0.000302271\n",
            "[48000]\tvalid_0's multi_logloss: 0.000251624\n",
            "[49000]\tvalid_0's multi_logloss: 0.000197046\n",
            "[50000]\tvalid_0's multi_logloss: 0.000194568\n",
            "[51000]\tvalid_0's multi_logloss: 0.000184516\n",
            "[52000]\tvalid_0's multi_logloss: 0.000152301\n",
            "[53000]\tvalid_0's multi_logloss: 0.000131243\n",
            "[54000]\tvalid_0's multi_logloss: 0.000127319\n",
            "[55000]\tvalid_0's multi_logloss: 0.00012199\n",
            "[56000]\tvalid_0's multi_logloss: 0.000114832\n",
            "[57000]\tvalid_0's multi_logloss: 0.000108871\n",
            "[58000]\tvalid_0's multi_logloss: 0.000111726\n",
            "[59000]\tvalid_0's multi_logloss: 0.000110397\n",
            "[60000]\tvalid_0's multi_logloss: 0.000112873\n",
            "Early stopping, best iteration is:\n",
            "[58442]\tvalid_0's multi_logloss: 0.000108006\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.427511\n",
            "[2000]\tvalid_0's multi_logloss: 0.203746\n",
            "[3000]\tvalid_0's multi_logloss: 0.117871\n",
            "[4000]\tvalid_0's multi_logloss: 0.0675985\n",
            "[5000]\tvalid_0's multi_logloss: 0.0447441\n",
            "[6000]\tvalid_0's multi_logloss: 0.0332668\n",
            "[7000]\tvalid_0's multi_logloss: 0.0257004\n",
            "[8000]\tvalid_0's multi_logloss: 0.0188366\n",
            "[9000]\tvalid_0's multi_logloss: 0.0130414\n",
            "[10000]\tvalid_0's multi_logloss: 0.00965626\n",
            "[11000]\tvalid_0's multi_logloss: 0.0057044\n",
            "[12000]\tvalid_0's multi_logloss: 0.00346761\n",
            "[13000]\tvalid_0's multi_logloss: 0.00239841\n",
            "[14000]\tvalid_0's multi_logloss: 0.00173329\n",
            "[15000]\tvalid_0's multi_logloss: 0.00115494\n",
            "[16000]\tvalid_0's multi_logloss: 0.000709268\n",
            "[17000]\tvalid_0's multi_logloss: 0.000470229\n",
            "[18000]\tvalid_0's multi_logloss: 0.000324655\n",
            "[19000]\tvalid_0's multi_logloss: 0.000249524\n",
            "[20000]\tvalid_0's multi_logloss: 0.00020054\n",
            "[21000]\tvalid_0's multi_logloss: 0.000171261\n",
            "[22000]\tvalid_0's multi_logloss: 0.00014331\n",
            "[23000]\tvalid_0's multi_logloss: 0.000101223\n",
            "[24000]\tvalid_0's multi_logloss: 7.17926e-05\n",
            "[25000]\tvalid_0's multi_logloss: 5.98976e-05\n",
            "[26000]\tvalid_0's multi_logloss: 4.42003e-05\n",
            "[27000]\tvalid_0's multi_logloss: 2.97171e-05\n",
            "[28000]\tvalid_0's multi_logloss: 2.23047e-05\n",
            "[29000]\tvalid_0's multi_logloss: 1.82534e-05\n",
            "[30000]\tvalid_0's multi_logloss: 1.46661e-05\n",
            "[31000]\tvalid_0's multi_logloss: 1.09953e-05\n",
            "[32000]\tvalid_0's multi_logloss: 8.39127e-06\n",
            "[33000]\tvalid_0's multi_logloss: 5.82013e-06\n",
            "[34000]\tvalid_0's multi_logloss: 4.10276e-06\n",
            "[35000]\tvalid_0's multi_logloss: 3.01093e-06\n",
            "[36000]\tvalid_0's multi_logloss: 2.20959e-06\n",
            "[37000]\tvalid_0's multi_logloss: 1.31704e-06\n",
            "[38000]\tvalid_0's multi_logloss: 8.58036e-07\n",
            "[39000]\tvalid_0's multi_logloss: 5.7121e-07\n",
            "[40000]\tvalid_0's multi_logloss: 3.90108e-07\n",
            "[41000]\tvalid_0's multi_logloss: 2.81717e-07\n",
            "[42000]\tvalid_0's multi_logloss: 2.34969e-07\n",
            "[43000]\tvalid_0's multi_logloss: 1.9183e-07\n",
            "[44000]\tvalid_0's multi_logloss: 1.68077e-07\n",
            "[45000]\tvalid_0's multi_logloss: 1.50991e-07\n",
            "[46000]\tvalid_0's multi_logloss: 1.34525e-07\n",
            "[47000]\tvalid_0's multi_logloss: 1.29611e-07\n",
            "[48000]\tvalid_0's multi_logloss: 1.23764e-07\n",
            "[49000]\tvalid_0's multi_logloss: 1.15501e-07\n",
            "[50000]\tvalid_0's multi_logloss: 1.05149e-07\n",
            "[51000]\tvalid_0's multi_logloss: 1.01934e-07\n",
            "[52000]\tvalid_0's multi_logloss: 9.92523e-08\n",
            "[53000]\tvalid_0's multi_logloss: 9.58929e-08\n",
            "[54000]\tvalid_0's multi_logloss: 9.12563e-08\n",
            "[55000]\tvalid_0's multi_logloss: 8.74751e-08\n",
            "[56000]\tvalid_0's multi_logloss: 8.40368e-08\n",
            "[57000]\tvalid_0's multi_logloss: 8.08799e-08\n",
            "[58000]\tvalid_0's multi_logloss: 7.85333e-08\n",
            "[59000]\tvalid_0's multi_logloss: 7.66804e-08\n",
            "[60000]\tvalid_0's multi_logloss: 7.50696e-08\n",
            "[61000]\tvalid_0's multi_logloss: 7.2504e-08\n",
            "[62000]\tvalid_0's multi_logloss: 6.99436e-08\n",
            "[63000]\tvalid_0's multi_logloss: 6.72955e-08\n",
            "[64000]\tvalid_0's multi_logloss: 6.51218e-08\n",
            "[65000]\tvalid_0's multi_logloss: 6.31206e-08\n",
            "[66000]\tvalid_0's multi_logloss: 6.17617e-08\n",
            "[67000]\tvalid_0's multi_logloss: 6.00334e-08\n",
            "[68000]\tvalid_0's multi_logloss: 5.85043e-08\n",
            "[69000]\tvalid_0's multi_logloss: 5.70067e-08\n",
            "[70000]\tvalid_0's multi_logloss: 5.49509e-08\n",
            "[71000]\tvalid_0's multi_logloss: 5.29294e-08\n",
            "[72000]\tvalid_0's multi_logloss: 5.1177e-08\n",
            "[73000]\tvalid_0's multi_logloss: 4.93728e-08\n",
            "[74000]\tvalid_0's multi_logloss: 4.75724e-08\n",
            "[75000]\tvalid_0's multi_logloss: 4.6653e-08\n",
            "[76000]\tvalid_0's multi_logloss: 4.57494e-08\n",
            "[77000]\tvalid_0's multi_logloss: 4.48459e-08\n",
            "[78000]\tvalid_0's multi_logloss: 4.33475e-08\n",
            "[79000]\tvalid_0's multi_logloss: 4.19598e-08\n",
            "[80000]\tvalid_0's multi_logloss: 4.09793e-08\n",
            "[81000]\tvalid_0's multi_logloss: 4.01829e-08\n",
            "[82000]\tvalid_0's multi_logloss: 4.00033e-08\n",
            "[83000]\tvalid_0's multi_logloss: 3.95047e-08\n",
            "[84000]\tvalid_0's multi_logloss: 3.91018e-08\n",
            "[85000]\tvalid_0's multi_logloss: 3.85607e-08\n",
            "[86000]\tvalid_0's multi_logloss: 3.80873e-08\n",
            "[87000]\tvalid_0's multi_logloss: 3.76689e-08\n",
            "[88000]\tvalid_0's multi_logloss: 3.73277e-08\n",
            "[89000]\tvalid_0's multi_logloss: 3.69902e-08\n",
            "[90000]\tvalid_0's multi_logloss: 3.66093e-08\n",
            "[91000]\tvalid_0's multi_logloss: 3.62263e-08\n",
            "[92000]\tvalid_0's multi_logloss: 3.58629e-08\n",
            "[93000]\tvalid_0's multi_logloss: 3.5519e-08\n",
            "[94000]\tvalid_0's multi_logloss: 3.52139e-08\n",
            "[95000]\tvalid_0's multi_logloss: 3.49876e-08\n",
            "[96000]\tvalid_0's multi_logloss: 3.47711e-08\n",
            "[97000]\tvalid_0's multi_logloss: 3.45638e-08\n",
            "[98000]\tvalid_0's multi_logloss: 3.43671e-08\n",
            "[99000]\tvalid_0's multi_logloss: 3.41769e-08\n",
            "[100000]\tvalid_0's multi_logloss: 3.39813e-08\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[99999]\tvalid_0's multi_logloss: 3.39798e-08\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.448668\n",
            "[2000]\tvalid_0's multi_logloss: 0.317406\n",
            "[3000]\tvalid_0's multi_logloss: 0.290416\n",
            "[4000]\tvalid_0's multi_logloss: 0.287345\n",
            "[5000]\tvalid_0's multi_logloss: 0.320448\n",
            "[6000]\tvalid_0's multi_logloss: 0.341693\n",
            "Early stopping, best iteration is:\n",
            "[4054]\tvalid_0's multi_logloss: 0.286559\n",
            "Training until validation scores don't improve for 2000 rounds.\n",
            "[1000]\tvalid_0's multi_logloss: 0.367751\n",
            "[2000]\tvalid_0's multi_logloss: 0.148782\n",
            "[3000]\tvalid_0's multi_logloss: 0.0836294\n",
            "[4000]\tvalid_0's multi_logloss: 0.0647543\n",
            "[5000]\tvalid_0's multi_logloss: 0.059218\n",
            "[6000]\tvalid_0's multi_logloss: 0.0512639\n",
            "[7000]\tvalid_0's multi_logloss: 0.0492581\n",
            "[8000]\tvalid_0's multi_logloss: 0.0455447\n",
            "[9000]\tvalid_0's multi_logloss: 0.0438309\n",
            "[10000]\tvalid_0's multi_logloss: 0.0374834\n",
            "[11000]\tvalid_0's multi_logloss: 0.034088\n",
            "[12000]\tvalid_0's multi_logloss: 0.0260884\n",
            "[13000]\tvalid_0's multi_logloss: 0.0218306\n",
            "[14000]\tvalid_0's multi_logloss: 0.0182975\n",
            "[15000]\tvalid_0's multi_logloss: 0.0166135\n",
            "[16000]\tvalid_0's multi_logloss: 0.0161465\n",
            "[17000]\tvalid_0's multi_logloss: 0.0123543\n",
            "[18000]\tvalid_0's multi_logloss: 0.010803\n",
            "[19000]\tvalid_0's multi_logloss: 0.0102642\n",
            "[20000]\tvalid_0's multi_logloss: 0.00861445\n",
            "[21000]\tvalid_0's multi_logloss: 0.00701618\n",
            "[22000]\tvalid_0's multi_logloss: 0.00598532\n",
            "[23000]\tvalid_0's multi_logloss: 0.00458519\n",
            "[24000]\tvalid_0's multi_logloss: 0.00314967\n",
            "[25000]\tvalid_0's multi_logloss: 0.00192994\n",
            "[26000]\tvalid_0's multi_logloss: 0.00187156\n",
            "[27000]\tvalid_0's multi_logloss: 0.0019072\n",
            "Early stopping, best iteration is:\n",
            "[25316]\tvalid_0's multi_logloss: 0.00174236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "베이지안 최적화 돌려서 일단 어느정도 성능 나오도록 하자."
      ],
      "metadata": {
        "id": "GqxHQEiklyH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=50).split(train_X, train_y)\n",
        "\n",
        "xgb_models = []\n",
        "xgb_scores = []\n",
        "\n",
        "for (ktrain, kvalid) in kfold:\n",
        "  model = xgb.XGBClassifier(objective='multi:softmax', n_estimators=30000,  num_class=3, learning_rate=0.05, random_state=413, eval_metric=['mlogloss'])\n",
        "  model.fit(train_X.iloc[ktrain, :], train_y[ktrain], verbose=1000, eval_set=[(train_X.iloc[kvalid, :], train_y[kvalid])], early_stopping_rounds=1000)\n",
        "  iter = model.best_iteration\n",
        "  pred = model.predict_proba(train_X.iloc[kvalid, :])\n",
        "  score = log_loss(train_y[kvalid], pred)\n",
        "  xgb_scores.append(score)\n",
        "  xgb_models.append(model)"
      ],
      "metadata": {
        "id": "xnKYdhbJkJdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for idx in np.argsort(lgbm_scores)[:1]:\n",
        "  pred = lgbm_models[idx].predict(test_X)\n",
        "  preds.append(pred)\n",
        "final_pred_lgbm = np.sum(preds, axis=0)\n",
        "preds = []\n",
        "for idx in np.argsort(xgb_scores)[:1]:\n",
        "  pred = xgb_models[idx].predict_proba(test_X)\n",
        "  preds.append(pred)\n",
        "final_pred_xgb = np.sum(preds, axis=0)"
      ],
      "metadata": {
        "id": "DzZGI5u2qAYI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pred = final_pred_lgbm + final_pred_xgb"
      ],
      "metadata": {
        "id": "iBOuqLtIEsBT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission['class'] = np.argmax(final_pred, axis=1)\n",
        "dicClassRev = {0: 'A', 1: 'B', 2: 'C'}\n",
        "submission['class'] = submission['class'].apply(lambda x: dicClassRev[x])\n",
        "submission.to_csv('submission_lgbm_xgb.csv', index=False)"
      ],
      "metadata": {
        "id": "zfnra5XcsBWU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "일단 이 전처리로 성능 향상을 최대로 해봅시다.\n",
        "crossfold방식으로 5개 앙상블\n",
        "다른 모델과 앙상블(xgboost)"
      ],
      "metadata": {
        "id": "DBsrPuXwteCr"
      }
    }
  ]
}